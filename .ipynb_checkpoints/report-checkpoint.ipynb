{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Ticket Writing Machine!\n",
    "### DS4400 Final Project\n",
    "### by Benjamin Kosiborod and Victoria Staada\n",
    "&nbsp;\n",
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fNIEk9XwIQ0H"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# All project imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5-mTrASmIdSP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/centos7/anaconda3/2020.02/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (17,18,20,22,23,29,30,31,32,36,38,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv('https://data.cityofnewyork.us/resource/faiq-9dfq.csv?$limit=12000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data so that we can\n",
    "# manipulate the data and re-copy\n",
    "# if we make a mistake\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       summons_number  violation_code  street_code1  street_code2  \\\n",
      "count    1.146751e+07    1.146751e+07  1.146751e+07  1.146751e+07   \n",
      "mean     7.474217e+09    3.377908e+01  2.562781e+04  2.119624e+04   \n",
      "std      2.268085e+09    1.985783e+01  2.246802e+04  2.193509e+04   \n",
      "min      1.028884e+09    0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%      8.500714e+09    2.000000e+01  9.130000e+03  0.000000e+00   \n",
      "50%      8.655880e+09    3.600000e+01  1.934000e+04  1.474000e+04   \n",
      "75%      8.694870e+09    4.000000e+01  3.618000e+04  3.427000e+04   \n",
      "max      8.768851e+09    9.900000e+01  9.802000e+04  9.831000e+04   \n",
      "\n",
      "       street_code3  vehicle_expiration_date  violation_location  \\\n",
      "count  1.146751e+07             1.146751e+07        9.589591e+06   \n",
      "mean   2.126681e+04             2.691894e+07        5.636025e+01   \n",
      "std    2.198500e+04             2.736702e+07        3.963513e+01   \n",
      "min    0.000000e+00             0.000000e+00        1.000000e+00   \n",
      "25%    0.000000e+00             2.018103e+07        1.900000e+01   \n",
      "50%    1.529000e+04             2.019093e+07        5.000000e+01   \n",
      "75%    3.435000e+04             2.020081e+07        9.000000e+01   \n",
      "max    9.828000e+04             8.888889e+07        9.720000e+02   \n",
      "\n",
      "       violation_precinct  issuer_precinct   issuer_code  date_first_observed  \\\n",
      "count        1.146751e+07     1.146751e+07  1.146751e+07         1.146751e+07   \n",
      "mean         4.713071e+01     5.211049e+01  3.343210e+05         2.774168e+05   \n",
      "std          4.181724e+01     7.045271e+01  1.917478e+05         2.350066e+06   \n",
      "min          0.000000e+00     0.000000e+00  0.000000e+00         0.000000e+00   \n",
      "25%          1.000000e+01     7.000000e+00  3.512120e+05         0.000000e+00   \n",
      "50%          4.000000e+01     3.400000e+01  3.619040e+05         0.000000e+00   \n",
      "75%          8.100000e+01     8.400000e+01  3.664660e+05         0.000000e+00   \n",
      "max          9.720000e+02     9.960000e+02  9.999780e+05         2.028082e+07   \n",
      "\n",
      "        law_section  unregistered_vehicle  vehicle_year  feet_from_curb  \\\n",
      "count  1.146751e+07              887035.0  1.146751e+07    1.146751e+07   \n",
      "mean   5.261089e+02                   0.0  1.564313e+03    1.155072e-01   \n",
      "std    2.723649e+02                   0.0  8.367438e+02    8.150393e-01   \n",
      "min    0.000000e+00                   0.0  0.000000e+00    0.000000e+00   \n",
      "25%    4.080000e+02                   0.0  2.001000e+03    0.000000e+00   \n",
      "50%    4.080000e+02                   0.0  2.011000e+03    0.000000e+00   \n",
      "75%    4.080000e+02                   0.0  2.016000e+03    0.000000e+00   \n",
      "max    1.180000e+03                   0.0  2.069000e+03    1.600000e+01   \n",
      "\n",
      "       no_standing_or_stopping  hydrant_violation  double_parking_violation  \n",
      "count                      0.0                0.0                       0.0  \n",
      "mean                       NaN                NaN                       NaN  \n",
      "std                        NaN                NaN                       NaN  \n",
      "min                        NaN                NaN                       NaN  \n",
      "25%                        NaN                NaN                       NaN  \n",
      "50%                        NaN                NaN                       NaN  \n",
      "75%                        NaN                NaN                       NaN  \n",
      "max                        NaN                NaN                       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Preview the data\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns that are mostly empty, \n",
    "# or do not have useful data\n",
    "df = df.drop(columns=['violation_post_code', 'violation_location', 'feet_from_curb', 'house_number', 'intersecting_street', 'date_first_observed', 'law_section', 'sub_division', 'violation_legal_code', 'violation_in_front_of_or', 'time_first_observed', 'issuer_code', 'issuer_command', 'issuer_squad', 'summons_number', 'plate_id', 'days_parking_in_effect', 'from_hours_in_effect', 'to_hours_in_effect', 'unregistered_vehicle', 'violation_description', 'no_standing_or_stopping', 'hydrant_violation', 'double_parking_violation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11467506 entries, 0 to 11467505\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Dtype \n",
      "---  ------                   ----- \n",
      " 0   registration_state       object\n",
      " 1   plate_type               object\n",
      " 2   issue_date               object\n",
      " 3   violation_code           int64 \n",
      " 4   vehicle_body_type        object\n",
      " 5   vehicle_make             object\n",
      " 6   issuing_agency           object\n",
      " 7   street_code1             int64 \n",
      " 8   street_code2             int64 \n",
      " 9   street_code3             int64 \n",
      " 10  vehicle_expiration_date  int64 \n",
      " 11  violation_precinct       int64 \n",
      " 12  issuer_precinct          int64 \n",
      " 13  violation_time           object\n",
      " 14  violation_county         object\n",
      " 15  street_name              object\n",
      " 16  vehicle_color            object\n",
      " 17  vehicle_year             int64 \n",
      " 18  meter_number             object\n",
      "dtypes: int64(8), object(11)\n",
      "memory usage: 1.6+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check columns left and their types\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of having meter numbers, change this column into a boolean value\n",
    "# for meter or no meter recorded at time of violation\n",
    "df['meter_number'] = df['meter_number'].apply(lambda x: 0 if x == '-' or pd.isnull(x) else 1)\n",
    "df = df.rename({'meter_number': 'meter?'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}\n",
    "for color in ('WH', 'W', 'w', 'white', 'White', 'WT', 'WHI', 'WH/', 'WHITE', 'Cream', 'CREAM', 'WT.', 'WHTE', 'WH YW', 'WHITW', 'HT', 'WHT', 'WHBL', 'WHB', 'WHO', 'WHGY', 'WHIT', 'WHG', 'WHRD', 'WHGR', 'WTE', 'WH.', 'WHBK', 'WHTN', 'WHT.', 'WHTIE', 'WHE', 'WHGL', 'W/B', 'CRM', 'WHBR', 'WHWH', 'WHOR', 'WG', 'WHYW', 'WHIE', 'WJ', 'WHLE'):\n",
    "    colors[color] = 'White'\n",
    "for color in ('Black', 'BLK', 'BK', 'black', 'BLK.', 'BK.', 'BLACK', 'BLW', 'BKGY', 'BK/', 'BKBL', 'BLCK', 'BKGR', 'BLWH', 'BLA', 'BKG', 'BLK.', 'BKTN', 'BKW', 'BKT', 'BKWH', 'BLAC', 'BLAK', 'BLTN', 'BLRD', 'BKBK', 'BLGL', 'BLKWH'):\n",
    "    colors[color] = 'Black'\n",
    "for color in ('GRY', 'Gray', 'GY/', 'GRAY', 'GY', 'GREY', 'grey', 'Grey', 'DKGRY', 'M.GRE', 'GY/GL', 'GRAYF', 'CHRAY', 'LTGY', 'DKGY', 'GYGY', 'GYBL', 'GYGR', 'GY.', 'GYB', 'GRA', 'GYRD', 'GYBK', 'GYTN', 'GYG', 'GYBR', 'GYWH', 'GRY.', 'GRAY.', 'ALUMI', 'GYT', 'GREY.', 'GYGL', 'Gray', 'GYPR', 'GY GR'):\n",
    "    colors[color] = 'Gray'\n",
    "for color in ('Silver', 'SILVER', 'SLV', 'SV', 'SL', 'SILV', 'SILVE', 'SIL', 'SILVR', 'SL.', 'STEEL', 'MET', 'SLVR', 'SLR', 'SIV', 'SLVER', 'SLIVE', 'SLVE', 'SIL.'):\n",
    "    colors[color] = 'Silver'\n",
    "for color in ('TAN', 'Beige', 'BEIGE', 'beige', 'BLD', 'ALMON', 'TN', 'LTTN', 'TNGY', 'BE', 'BIEGE', 'TNGR', 'DKTN', 'TN/', 'BEIG'):\n",
    "    colors[color] = 'Beige'\n",
    "for color in ('RED', 'red', 'RD', 'rd', 'Rd', 'Red', 'RO', 'BUGA', 'MAROO', 'MAR', 'MR', 'BUNGE', 'RDW', 'DKR', 'DKRD', 'RD/', 'BURG', 'BURGU', 'BUR', 'RDGY', 'RD.', 'RDT', 'RDBK', 'RDBL', 'MRPK', 'RDG', 'RDGR', 'RDWH', 'RDRD', 'RDTN', 'DKMR', 'RD BK', 'RED.', 'BURGA', 'MRGY', 'MRN', 'BUG', 'RE', 'RDBR', 'DKRED'):\n",
    "    colors[color] = 'Red'\n",
    "for color in ('BLUE', 'BL', 'BLLU', 'QBLUE', 'BUO', 'BLU', 'DKBL', 'BLG', 'BL/', 'BLGY', 'LTBL', 'BLGR', 'BLBL', 'DBL', 'BL.', 'BLB', 'LBL', 'BLBK', 'BLUE.', 'NAVY', 'BLRD'):\n",
    "    colors[color] = 'Blue'\n",
    "for color in ('GREEN', 'GR', 'GYN', 'GRN', 'LTGR', 'DKGR', 'GR/', 'GRE', 'GRGY', 'GRG', 'GRW', 'GRBL', 'GRGR', 'DGR', 'GRB', 'GREN', 'GRT', 'LGR', 'GREE', 'GRTN'):\n",
    "    colors[color] = 'Green'\n",
    "for color in ('YELLW', 'YEL', 'YELL', 'YELLO', 'YW', 'GOLDE', 'ORO', 'YOL', 'YLOW', 'YL', 'GL', 'GOLD', 'GLD', 'YLW', 'Y', 'YE', 'YLLW', 'YELLL'):\n",
    "    colors[color] = 'Yellow'\n",
    "for color in ('BROWN', 'BR', 'BR/GY', 'BON', 'BRWMN', 'BREIR', 'BEUG', 'BRWN', 'BRN', 'BRO', 'BRW', 'BWN', 'LTBR', 'BROW', 'BRZ', 'DKBR', 'BRBL', 'BRON', 'BRT'):\n",
    "    colors[color] = 'Brown'\n",
    "for color in ('LAVEN', 'PURPL', 'PR', 'PURP', 'PUR', 'DKRR'):\n",
    "    colors[color] = 'Purple'\n",
    "for color in ('OR', 'ORANGE', 'ORANG', 'ONG', 'O', 'OG', 'ORA', 'ORAN', 'ORWH', 'ORN'):\n",
    "    colors[color] = 'Orange'\n",
    "\n",
    "df['vehicle_color'] = df['vehicle_color'].apply(lambda row: colors.get(row, row))\n",
    "\n",
    "# Drop rows that are not categorized by the above, \n",
    "# as there as <500K such records out of 11.5M\n",
    "# and the colors begin to get more niche. We\n",
    "# suspect there is not enough data to accurately\n",
    "# make predictions for the remaining colors.\n",
    "df = df[df.vehicle_color.isin(colors.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.vehicle_year <= 2020) & (df.vehicle_year != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of null and non-stated vehicle makes, \n",
    "# as well as rows that contain makes where \n",
    "# there are less than 100 records\n",
    "df = df[pd.notnull(df.vehicle_make) \n",
    "        & (df.vehicle_make != 'NS/OT') \n",
    "        & (df.vehicle_make != 'FRE') \n",
    "        & (df.vehicle_make != 'STARC')\n",
    "        & (df.vehicle_make != 'BL/BI')\n",
    "        & (df.vehicle_make != 'COLLI')\n",
    "        & (df.vehicle_make != 'UNIFL')\n",
    "        & (df.vehicle_make != 'ORION')\n",
    "        & (df.vehicle_make != 'TSM')\n",
    "        & (df.vehicle_make != 'EASTO')]\n",
    "df = df.groupby('vehicle_make').filter(lambda x: len(x) > 100)\n",
    "\n",
    "makes = {\n",
    "    'FORD': 'Ford',\n",
    "    'TOYOT': 'Toyota',\n",
    "    'HONDA': 'Honda',\n",
    "    'NISSA': 'Nissan',\n",
    "    'CHEVR': 'Chevrolet',\n",
    "    'ME/BE': 'Mercedes-Benz',\n",
    "    'FREUH': 'Fruehauf',\n",
    "    'DODGE': 'Dodge',\n",
    "    'HYUND': 'Hyundai',\n",
    "    'JEEP': 'Jeep',\n",
    "    'LEXUS': 'Lexus',\n",
    "    'INTER': 'International Harvester',\n",
    "    'ACURA': 'Acura',\n",
    "    'INFIN': 'Infiniti',\n",
    "    'SUBAR': 'Subaru',\n",
    "    'VOLKS': 'Volkswagen',\n",
    "    'HIN': 'Hindustan Motors',\n",
    "    'CHRYS': 'Chrystler',\n",
    "    'AUDI': 'Audi',\n",
    "    'ISUZU': 'Isuzu',\n",
    "    'KIA': 'Kia',\n",
    "    'MAZDA': 'Mazda',\n",
    "    'MITSU': 'Mitsubishi',\n",
    "    'ROVER': 'Land Rover',\n",
    "    'CADIL': 'Cadillac',\n",
    "    'LINCO': 'Lincoln',\n",
    "    'VOLVO': 'Volvo',\n",
    "    'WORKH': 'Workhorse',\n",
    "    'KENWO': 'Kenworth',\n",
    "    'BUICK': 'Buick',\n",
    "    'SMART': 'smart',\n",
    "    'PETER': 'Peterbilt',\n",
    "    'MINI': 'Mini',\n",
    "    'PORSC': 'Porsche',\n",
    "    'MERCU': 'Mercury',\n",
    "    'JAGUA': 'Jaguar',\n",
    "    'FIAT': 'Fiat',\n",
    "    'SATUR': 'Saturn',\n",
    "    'PONTI': 'Pontiac',\n",
    "    'UTILI': 'Utility',\n",
    "    'MACK': 'Mack',\n",
    "    'TESLA': 'Tesla',\n",
    "    'SUZUK': 'Suzuki',\n",
    "    'UD': 'UD Trucks',\n",
    "    'MASE': 'Maserati',\n",
    "    'SAAB': 'Saab',\n",
    "    'HYUN': 'Hyundai',\n",
    "    'HUMME': 'Hummer',\n",
    "    'OLDSM': 'Oldsmobile',\n",
    "    'MCI': 'Motor Coach Industries',\n",
    "    'THOMA': 'Thomas Built Busses',\n",
    "    'IC': 'IC Bus',\n",
    "    'YAMAH': 'Yamaha',\n",
    "    'BENTL': 'Bentley',\n",
    "    'VANHO': 'Van Hool Bus',\n",
    "    'SPRI': 'Springdale RVs',\n",
    "    'KAWAS': 'Kawasaki',\n",
    "    'ALFAR': 'Alfa Romeo',\n",
    "    'PLYMO': 'Plymouth',\n",
    "    'HARLE': 'Harley Davidson',\n",
    "    'STERL': 'Sterling',\n",
    "    'VESPA': 'Vespa',\n",
    "    'UPS': 'UPS Truck',\n",
    "    'VPG': 'Vehicle Production Group',\n",
    "    'PREVO': 'Prevost RVs',\n",
    "    'GEO': 'Geo',\n",
    "    'NAVIS': 'Navistar',\n",
    "    'FERRA': 'Ferrari',\n",
    "    'TRIUM': 'Triumph',\n",
    "    'DUCAT': 'Ducati',\n",
    "    'ZENIT': 'Zenith',\n",
    "    'GENES': 'Genesis',\n",
    "    'SCION': 'Scion',\n",
    "    'HINO': 'Hino Motors',\n",
    "    'ROLLS': 'Rolls Royce',\n",
    "    'LAMBO': 'Lamborgini',\n",
    "    'CHECK': 'Checker Motors',\n",
    "    'SETRA': 'Setra Coach',\n",
    "    'ACUR': 'Acura',\n",
    "    'GREAT': 'Great Dane',\n",
    "    'LEXU': 'Lexus',\n",
    "    'SMITH': 'Smith Electric Vehicles',\n",
    "}\n",
    "\n",
    "df['vehicle_make'] = df['vehicle_make'].apply(lambda row: makes.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up violation county\n",
    "counties = {\n",
    "    'NY': 'Manhattan',\n",
    "    'K': 'Brooklyn',\n",
    "    'Q': 'Queens',\n",
    "    'BX': 'Bronx',\n",
    "    'BK': 'Brooklyn',\n",
    "    'QN': 'Queens',\n",
    "    'R': 'Staten Island',\n",
    "    'ST': 'Staten Island',\n",
    "    'MN': 'Manhattan',\n",
    "    'QUEEN': 'Queens',\n",
    "}\n",
    "df['violation_county'] = df['violation_county'].apply(lambda row: counties.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up registration state\n",
    "df = df[pd.notnull(df.registration_state) & (df.registration_state != '99')]\n",
    "state = {\n",
    "    'GV': 'U.S. Government',\n",
    "    'DP': 'U.S. Department of State',\n",
    "}\n",
    "df['registration_state'] = df['registration_state'].apply(lambda row: state.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df.plate_type) & (df.plate_type != '999')]\n",
    "df = df.groupby('plate_type').filter(lambda x: len(x) > 100)\n",
    "plate_types = {\n",
    "    'PAS': 'Passenger',\n",
    "    'COM': 'Commercial',\n",
    "    'OMT': 'Taxi Omnibus',\n",
    "    'OMS': 'Special Omnibus Rentals',\n",
    "    'SRF': 'Special Passenger',\n",
    "    'APP': 'Apportioned',\n",
    "    'TRC': 'Tractor',\n",
    "    'ORG': 'Organizational',\n",
    "    'OMR': 'Omnibus',\n",
    "    'MED': 'Medical Doctor',\n",
    "    'SPO': 'Sports Passenger',\n",
    "    'OML': 'Livery Omnibus',\n",
    "    'PSD': 'Political Subdivision',\n",
    "    'SCL': 'School Car',\n",
    "    'IRP': 'International Reg Plan',\n",
    "    'TOW': 'Tow Truck',\n",
    "    'MOT': 'Motorcycle',\n",
    "    'RGL': 'Regional',\n",
    "    'VAS': 'Volunteer Ambulance Services',\n",
    "    'ITP': 'In Transit Permit',\n",
    "    'SRN': 'Special Passenger Judges/Officials',\n",
    "    'HIS': 'Historical',\n",
    "    'TRA': 'Transporter',\n",
    "    'CHC': 'Household Carrier Commercial',\n",
    "    'STA': 'State Agencies',\n",
    "    'AGR': 'Agricultural',\n",
    "    'AMB': 'Ambulance',\n",
    "    'PHS': 'Pearl Harbor Survivors',\n",
    "    'AYG': 'Army National Guard',\n",
    "    'RGC': 'Regional Commercial',\n",
    "    'ORC': 'Organizational Commercial',\n",
    "    'TRL': 'Regular Trailer',\n",
    "    'HAM': 'HAM Operator',\n",
    "    'DLR': 'Dealer',\n",
    "}\n",
    "df['plate_type'] = df['plate_type'].apply(lambda row: plate_types.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up issue date, get rid of dates not in 2019 fiscal year\n",
    "# (includes 2018 and 2019 issue dates)\n",
    "df.issue_date = pd.to_datetime(df['issue_date'], errors='coerce')\n",
    "df = df[df.issue_date.dt.year.isin([2018, 2019])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up vehicle body type, get rid of null or unknown\n",
    "# body types, and the least popular ones.\n",
    "df = df[pd.notnull(df.vehicle_body_type) \n",
    "        & (df.vehicle_body_type != 'OLNE')\n",
    "        & (df.vehicle_body_type != 'LL')\n",
    "        & (df.vehicle_body_type != 'APUR')\n",
    "        & (df.vehicle_body_type != 'CW')\n",
    "        & (df.vehicle_body_type != 'O')\n",
    "        & (df.vehicle_body_type != 'EP')\n",
    "        & (df.vehicle_body_type != 'OM')]\n",
    "df = df.groupby('vehicle_body_type').filter(lambda x: len(x) > 100)\n",
    "body_types = {\n",
    "    'SUBN': 'Suburban',\n",
    "    '4DSD': '4 Door Sedan',\n",
    "    'VAN': 'Van',\n",
    "    'DELV': 'Delivery',\n",
    "    'PICK': 'Pickup Truck',\n",
    "    '2DSD': '2 Door Sedan',\n",
    "    'SDN': 'Sedan',\n",
    "    'REFG': 'Refridgerated',\n",
    "    'UTIL': 'Utility',\n",
    "    'TAXI': 'Taxi',\n",
    "    '4 DR': '4 Door',\n",
    "    '4D': '4 Door',\n",
    "    'TRAC': 'Tractor',\n",
    "    'CONV': 'Convertible',\n",
    "    'WAGO': 'Wagon',\n",
    "    'BUS': 'Bus',\n",
    "    'FLAT': 'Flatbed Truck',\n",
    "    'P-U': 'Pickup Truck',\n",
    "    'DUMP': 'Dump Truck',\n",
    "    'UT': 'Utility',\n",
    "    'MCY': 'Motorcycle',\n",
    "    'TRK': 'Truck',\n",
    "    '4W': '4 Door Wagon',\n",
    "    'TOW': 'Tow Truck',\n",
    "    'PKUP': 'Pickup Truck',\n",
    "    '4S': '4 Door Sedan',\n",
    "    'SU': 'Sport Utility Vehicle',\n",
    "    'STAK': 'Stake Truck',\n",
    "    '2 DR': '2 Door',\n",
    "    'MP': 'Moped',\n",
    "    'VN': 'Van',\n",
    "    'TANK': 'Tank Truck',\n",
    "    'SW': 'Station Wagon',\n",
    "    'FOUR': '4 Door',\n",
    "    'SEDN': 'Sedan',\n",
    "    'TK': 'Truck',\n",
    "    '2D': '2 Door',\n",
    "    'SD': 'Sedan',\n",
    "    'PK': 'Pickup Truck',\n",
    "    'SV': 'Sports Van',\n",
    "    '4H': '4 Door Hatchback',\n",
    "    'TR/C': 'Truck Crane',\n",
    "    'CON': 'Convertible',\n",
    "    'TRUC': 'Truck',\n",
    "    'LIM': 'Limousine',\n",
    "    'CP': 'Coupe',\n",
    "    'SEDA': 'Sedan',\n",
    "    '4DOO': '4 Door',\n",
    "    '5D': '5 Door',\n",
    "    'SWT': 'Small-Wheel Truck',\n",
    "    'CV': 'Convertible',\n",
    "    'H/WH': 'Motorhome',\n",
    "    'CMIX': 'Cement Mixer',\n",
    "    '4DSE': '4 Door Sedan',\n",
    "    'TWOD': '2 Door',\n",
    "    'TRL': 'Trailer',\n",
    "    'MC': 'Motorcycle',\n",
    "    'REF': 'Refridgerated',\n",
    "    'TT': 'Tractor Trailer',\n",
    "    'TRC': 'Tractor',\n",
    "    'TRLR': 'Trailer',\n",
    "    'BOAT': 'Boat Trailer',\n",
    "    'ES': 'Station Wagon',\n",
    "    'TRAI': 'Trailer',\n",
    "    'TR': 'Truck',\n",
    "    '2S': '2 Door Sedan',\n",
    "    'HRSE': 'Hearse',\n",
    "    'TLR': 'Trailer',\n",
    "    'SPOR': 'Sports Car',\n",
    "    'SUV': 'SUV',\n",
    "    'MOT': 'Motorcycle',\n",
    "    '2H': '2 Door Hatchback',\n",
    "    'SUBU': 'Suburban',\n",
    "    'TRT': 'Tractor Trailer',\n",
    "    'LIMO': 'Limousine',\n",
    "}\n",
    "df['vehicle_body_type'] = df['vehicle_body_type'].apply(lambda row: body_types.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each street can be encoded with a 5-digit street code\n",
    "# Each ticket has 3 street codes, because street code 1 \n",
    "# denotes the \"on\" street, while street codes 2 & 3\n",
    "# denote the \"cross\" steets. For example, Lexington Ave\n",
    "# between E 42nd and E 45th is a location, where the \n",
    "# car was parked on Lexington Ave, between E 42nd and E 45th streets.\n",
    "# See below link for more detail:\n",
    "# https://nycplanning.github.io/Geosupport-UPG/chapters/chapterVII/section03/\n",
    "df = df[(df.street_code1 != 0) & (pd.notnull(df.street_code1))\n",
    "   & (df.street_code2 != 0) & (pd.notnull(df.street_code2))\n",
    "   & (df.street_code3 != 0) & (pd.notnull(df.street_code3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.vehicle_expiration_date != 0) & (df.vehicle_expiration_date != 88880088)]\n",
    "df.vehicle_expiration_date = pd.to_datetime(df['vehicle_expiration_date'], format='%Y%m%d',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up violation codes. \n",
    "# 1-99 are valid codes.\n",
    "df = df[(df.violation_code > 0) & (df.violation_code < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up violation & issuer precincts, \n",
    "# get rid of invalid precinct numbers\n",
    "valid_precincts = [1, 5, 6, 7, 9, 10, 13, 14, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 30, \n",
    "                   32, 33, 34, 40, 41, 42, 43, 44, 45, 46,47, 48, 49, 50, 52, 60, 61, \n",
    "                   62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 83, \n",
    "                   84, 88, 90, 94, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, \n",
    "                   110, 111, 112, 113, 114, 115, 120, 121, 122, 123]\n",
    "df = df[df.violation_precinct.isin(valid_precincts)]\n",
    "df = df[df.issuer_precinct.isin(valid_precincts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/centos7/anaconda3/2020.02/lib/python3.7/site-packages/pandas/core/strings.py:1952: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Clean up violation time by removing\n",
    "# NaNs and restricting rows to only those that\n",
    "# match the regex pattern given. This allows\n",
    "# us to standardize the time format to a 12-hour\n",
    "# format with \"A\" or \"P\" at the end, denoting AM/PM\n",
    "df = df[(pd.notnull(df.violation_time)) & (df.violation_time.str.contains('(1[012]|0[1-9])[0-5][0-9](A|P)', regex=True, na=False))]\n",
    "df.violation_time = df.violation_time.apply(lambda row: float(row[:-1]) if row[4] == 'A' else float(row[:-1])+1200)\n",
    "df.violation_time = df.violation_time.apply(lambda row: row - 2400 if row / 2400 >= 1 else row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, drop all rows where NaN values exist\n",
    "df = df.dropna()\n",
    "\n",
    "# Reset the index so that the DataFrame is easier to work with\n",
    "df = df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to sample of 100K for training\n",
    "data = df.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and target\n",
    "# Dropping street name because we will use it as a reference\n",
    "# Rather than a feature for training\n",
    "features = data.drop(columns=[\"violation_code\", \"street_name\"])\n",
    "target = data.violation_code\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "# Encode and scale features\n",
    "encoded_columns = ['registration_state', 'plate_type', 'vehicle_body_type', 'vehicle_make', 'issuing_agency', 'violation_county', 'vehicle_color']\n",
    "categories = [features[column].unique() for column in encoded_columns]\n",
    "encoder = OrdinalEncoder(categories=categories).fit(X_train[encoded_columns])\n",
    "\n",
    "X_train_enc = X_train.copy()\n",
    "X_test_enc = X_test.copy()\n",
    "X_train_enc[encoded_columns] = encoder.transform(X_train[encoded_columns])\n",
    "X_test_enc[encoded_columns] = encoder.transform(X_test[encoded_columns])\n",
    "\n",
    "# Encode Datetime\n",
    "datetime_columns = ['issue_date', 'vehicle_expiration_date']\n",
    "X_train_enc[datetime_columns] = X_train_enc[datetime_columns].astype(int)\n",
    "X_test_enc[datetime_columns] = X_test_enc[datetime_columns].astype(int)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler().fit(X_train_enc)\n",
    "X_train_scaled = scaler.transform(X_train_enc)\n",
    "X_test_scaled = scaler.transform(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for outliers\n",
    "iforest = IsolationForest().fit(X_train_scaled)\n",
    "train_outliers = iforest.predict(X_train_scaled)\n",
    "test_outliers = iforest.predict(X_test_scaled)\n",
    "\n",
    "train_non_outliers = train_outliers != -1\n",
    "test_non_outliers = test_outliers != -1\n",
    "\n",
    "X_train, y_train = X_train_scaled[train_non_outliers, :], y_train[train_non_outliers]\n",
    "X_test, y_test = X_test_scaled[test_non_outliers, :], y_test[test_non_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_train, y_pred_train, y_test, y_pred_test, classifier_name):\n",
    "    '''Prints classification metrics for the given classifier_name\n",
    "       Input: y_true and y_predicted for both training and testing, as well as classifier name as a string\n",
    "       Output: None, prints report of accuracy metrics as well as classification report'''\n",
    "    print(f\"{classifier_name}:\")\n",
    "    print(\"\\tTraining:\")\n",
    "    print(\"\\t\\tAccuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"\\t\\tError:\", 1-accuracy_score(y_train, y_pred_train))\n",
    "    print(\"\\t\\tClassification Report:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(\"\\tTesting:\")\n",
    "    print(\"\\t\\tAccuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "    print(\"\\t\\tError:\", 1-accuracy_score(y_test, y_pred_test))\n",
    "    print(\"\\t\\tClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, and evaluate kNN\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "y_pred_train = knn.predict(X_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "metrics(y_train, y_pred_train, y_test, y_pred_test, 'kNN Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there is no difference between any K value that we try, so kNN is likely a poor model for our data. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPr0dZ4wyC8oM28XFuSJtJg",
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
