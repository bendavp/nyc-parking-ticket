{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Ticket Writing Machine!\n",
    "### DS4400 Final Project\n",
    "### by Benjamin Kosiborod and Victoria Staada\n",
    "&nbsp;\n",
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "fNIEk9XwIQ0H"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# All project imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, MaxPooling3D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, label_binarize\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, precision_recall_fscore_support, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5-mTrASmIdSP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (17,18,20,22,23,29,30,31,32,36,38,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv('https://data.cityofnewyork.us/resource/faiq-9dfq.csv?$limit=12000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data so that we can\n",
    "# manipulate the data and re-copy\n",
    "# if we make a mistake\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       summons_number  violation_code  street_code1  street_code2  \\\n",
      "count    1.146751e+07    1.146751e+07  1.146751e+07  1.146751e+07   \n",
      "mean     7.474217e+09    3.377908e+01  2.562781e+04  2.119624e+04   \n",
      "std      2.268085e+09    1.985783e+01  2.246802e+04  2.193509e+04   \n",
      "min      1.028884e+09    0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%      8.500714e+09    2.000000e+01  9.130000e+03  0.000000e+00   \n",
      "50%      8.655880e+09    3.600000e+01  1.934000e+04  1.474000e+04   \n",
      "75%      8.694870e+09    4.000000e+01  3.618000e+04  3.427000e+04   \n",
      "max      8.768851e+09    9.900000e+01  9.802000e+04  9.831000e+04   \n",
      "\n",
      "       street_code3  vehicle_expiration_date  violation_location  \\\n",
      "count  1.146751e+07             1.146751e+07        9.589591e+06   \n",
      "mean   2.126681e+04             2.691894e+07        5.636025e+01   \n",
      "std    2.198500e+04             2.736702e+07        3.963513e+01   \n",
      "min    0.000000e+00             0.000000e+00        1.000000e+00   \n",
      "25%    0.000000e+00             2.018103e+07        1.900000e+01   \n",
      "50%    1.529000e+04             2.019093e+07        5.000000e+01   \n",
      "75%    3.435000e+04             2.020081e+07        9.000000e+01   \n",
      "max    9.828000e+04             8.888889e+07        9.720000e+02   \n",
      "\n",
      "       violation_precinct  issuer_precinct   issuer_code  date_first_observed  \\\n",
      "count        1.146751e+07     1.146751e+07  1.146751e+07         1.146751e+07   \n",
      "mean         4.713071e+01     5.211049e+01  3.343210e+05         2.774168e+05   \n",
      "std          4.181724e+01     7.045271e+01  1.917478e+05         2.350066e+06   \n",
      "min          0.000000e+00     0.000000e+00  0.000000e+00         0.000000e+00   \n",
      "25%          1.000000e+01     7.000000e+00  3.512120e+05         0.000000e+00   \n",
      "50%          4.000000e+01     3.400000e+01  3.619040e+05         0.000000e+00   \n",
      "75%          8.100000e+01     8.400000e+01  3.664660e+05         0.000000e+00   \n",
      "max          9.720000e+02     9.960000e+02  9.999780e+05         2.028082e+07   \n",
      "\n",
      "        law_section  unregistered_vehicle  vehicle_year  feet_from_curb  \\\n",
      "count  1.146751e+07              887035.0  1.146751e+07    1.146751e+07   \n",
      "mean   5.261089e+02                   0.0  1.564313e+03    1.155072e-01   \n",
      "std    2.723649e+02                   0.0  8.367438e+02    8.150393e-01   \n",
      "min    0.000000e+00                   0.0  0.000000e+00    0.000000e+00   \n",
      "25%    4.080000e+02                   0.0  2.001000e+03    0.000000e+00   \n",
      "50%    4.080000e+02                   0.0  2.011000e+03    0.000000e+00   \n",
      "75%    4.080000e+02                   0.0  2.016000e+03    0.000000e+00   \n",
      "max    1.180000e+03                   0.0  2.069000e+03    1.600000e+01   \n",
      "\n",
      "       no_standing_or_stopping  hydrant_violation  double_parking_violation  \n",
      "count                      0.0                0.0                       0.0  \n",
      "mean                       NaN                NaN                       NaN  \n",
      "std                        NaN                NaN                       NaN  \n",
      "min                        NaN                NaN                       NaN  \n",
      "25%                        NaN                NaN                       NaN  \n",
      "50%                        NaN                NaN                       NaN  \n",
      "75%                        NaN                NaN                       NaN  \n",
      "max                        NaN                NaN                       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Preview the data\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns that are mostly empty, \n",
    "# or do not have useful data\n",
    "df = df.drop(columns=['violation_post_code', 'violation_location', 'feet_from_curb', 'house_number', 'intersecting_street', 'date_first_observed', 'law_section', 'sub_division', 'violation_legal_code', 'violation_in_front_of_or', 'time_first_observed', 'issuer_code', 'issuer_command', 'issuer_squad', 'summons_number', 'plate_id', 'days_parking_in_effect', 'from_hours_in_effect', 'to_hours_in_effect', 'unregistered_vehicle', 'violation_description', 'no_standing_or_stopping', 'hydrant_violation', 'double_parking_violation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11467506 entries, 0 to 11467505\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Dtype \n",
      "---  ------                   ----- \n",
      " 0   registration_state       object\n",
      " 1   plate_type               object\n",
      " 2   issue_date               object\n",
      " 3   violation_code           int64 \n",
      " 4   vehicle_body_type        object\n",
      " 5   vehicle_make             object\n",
      " 6   issuing_agency           object\n",
      " 7   street_code1             int64 \n",
      " 8   street_code2             int64 \n",
      " 9   street_code3             int64 \n",
      " 10  vehicle_expiration_date  int64 \n",
      " 11  violation_precinct       int64 \n",
      " 12  issuer_precinct          int64 \n",
      " 13  violation_time           object\n",
      " 14  violation_county         object\n",
      " 15  street_name              object\n",
      " 16  vehicle_color            object\n",
      " 17  vehicle_year             int64 \n",
      " 18  meter_number             object\n",
      "dtypes: int64(8), object(11)\n",
      "memory usage: 1.6+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check columns left and their types\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of having meter numbers, change this column into a boolean value\n",
    "# for meter or no meter recorded at time of violation\n",
    "df['meter_number'] = df['meter_number'].apply(lambda x: 0 if x == '-' or pd.isnull(x) else 1)\n",
    "df = df.rename({'meter_number': 'meter?'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}\n",
    "for color in ('WH', 'W', 'w', 'white', 'White', 'WT', 'WHI', 'WH/', 'WHITE', 'Cream', 'CREAM', 'WT.', 'WHTE', 'WH YW', 'WHITW', 'HT', 'WHT', 'WHBL', 'WHB', 'WHO', 'WHGY', 'WHIT', 'WHG', 'WHRD', 'WHGR', 'WTE', 'WH.', 'WHBK', 'WHTN', 'WHT.', 'WHTIE', 'WHE', 'WHGL', 'W/B', 'CRM', 'WHBR', 'WHWH', 'WHOR', 'WG', 'WHYW', 'WHIE', 'WJ', 'WHLE'):\n",
    "    colors[color] = 'White'\n",
    "for color in ('Black', 'BLK', 'BK', 'black', 'BLK.', 'BK.', 'BLACK', 'BLW', 'BKGY', 'BK/', 'BKBL', 'BLCK', 'BKGR', 'BLWH', 'BLA', 'BKG', 'BLK.', 'BKTN', 'BKW', 'BKT', 'BKWH', 'BLAC', 'BLAK', 'BLTN', 'BLRD', 'BKBK', 'BLGL', 'BLKWH'):\n",
    "    colors[color] = 'Black'\n",
    "for color in ('GRY', 'Gray', 'GY/', 'GRAY', 'GY', 'GREY', 'grey', 'Grey', 'DKGRY', 'M.GRE', 'GY/GL', 'GRAYF', 'CHRAY', 'LTGY', 'DKGY', 'GYGY', 'GYBL', 'GYGR', 'GY.', 'GYB', 'GRA', 'GYRD', 'GYBK', 'GYTN', 'GYG', 'GYBR', 'GYWH', 'GRY.', 'GRAY.', 'ALUMI', 'GYT', 'GREY.', 'GYGL', 'Gray', 'GYPR', 'GY GR'):\n",
    "    colors[color] = 'Gray'\n",
    "for color in ('Silver', 'SILVER', 'SLV', 'SV', 'SL', 'SILV', 'SILVE', 'SIL', 'SILVR', 'SL.', 'STEEL', 'MET', 'SLVR', 'SLR', 'SIV', 'SLVER', 'SLIVE', 'SLVE', 'SIL.'):\n",
    "    colors[color] = 'Silver'\n",
    "for color in ('TAN', 'Beige', 'BEIGE', 'beige', 'BLD', 'ALMON', 'TN', 'LTTN', 'TNGY', 'BE', 'BIEGE', 'TNGR', 'DKTN', 'TN/', 'BEIG'):\n",
    "    colors[color] = 'Beige'\n",
    "for color in ('RED', 'red', 'RD', 'rd', 'Rd', 'Red', 'RO', 'BUGA', 'MAROO', 'MAR', 'MR', 'BUNGE', 'RDW', 'DKR', 'DKRD', 'RD/', 'BURG', 'BURGU', 'BUR', 'RDGY', 'RD.', 'RDT', 'RDBK', 'RDBL', 'MRPK', 'RDG', 'RDGR', 'RDWH', 'RDRD', 'RDTN', 'DKMR', 'RD BK', 'RED.', 'BURGA', 'MRGY', 'MRN', 'BUG', 'RE', 'RDBR', 'DKRED'):\n",
    "    colors[color] = 'Red'\n",
    "for color in ('BLUE', 'BL', 'BLLU', 'QBLUE', 'BUO', 'BLU', 'DKBL', 'BLG', 'BL/', 'BLGY', 'LTBL', 'BLGR', 'BLBL', 'DBL', 'BL.', 'BLB', 'LBL', 'BLBK', 'BLUE.', 'NAVY', 'BLRD'):\n",
    "    colors[color] = 'Blue'\n",
    "for color in ('GREEN', 'GR', 'GYN', 'GRN', 'LTGR', 'DKGR', 'GR/', 'GRE', 'GRGY', 'GRG', 'GRW', 'GRBL', 'GRGR', 'DGR', 'GRB', 'GREN', 'GRT', 'LGR', 'GREE', 'GRTN'):\n",
    "    colors[color] = 'Green'\n",
    "for color in ('YELLW', 'YEL', 'YELL', 'YELLO', 'YW', 'GOLDE', 'ORO', 'YOL', 'YLOW', 'YL', 'GL', 'GOLD', 'GLD', 'YLW', 'Y', 'YE', 'YLLW', 'YELLL'):\n",
    "    colors[color] = 'Yellow'\n",
    "for color in ('BROWN', 'BR', 'BR/GY', 'BON', 'BRWMN', 'BREIR', 'BEUG', 'BRWN', 'BRN', 'BRO', 'BRW', 'BWN', 'LTBR', 'BROW', 'BRZ', 'DKBR', 'BRBL', 'BRON', 'BRT'):\n",
    "    colors[color] = 'Brown'\n",
    "for color in ('LAVEN', 'PURPL', 'PR', 'PURP', 'PUR', 'DKRR'):\n",
    "    colors[color] = 'Purple'\n",
    "for color in ('OR', 'ORANGE', 'ORANG', 'ONG', 'O', 'OG', 'ORA', 'ORAN', 'ORWH', 'ORN'):\n",
    "    colors[color] = 'Orange'\n",
    "\n",
    "df['vehicle_color'] = df['vehicle_color'].apply(lambda row: colors.get(row, row))\n",
    "\n",
    "# Drop rows that are not categorized by the above, \n",
    "# as there as <500K such records out of 11.5M\n",
    "# and the colors begin to get more niche. We\n",
    "# suspect there is not enough data to accurately\n",
    "# make predictions for the remaining colors.\n",
    "df = df[df.vehicle_color.isin(colors.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.vehicle_year <= 2020) & (df.vehicle_year != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of null and non-stated vehicle makes, \n",
    "# as well as rows that contain makes where \n",
    "# there are less than 100 records\n",
    "df = df[pd.notnull(df.vehicle_make) \n",
    "        & (df.vehicle_make != 'NS/OT') \n",
    "        & (df.vehicle_make != 'FRE') \n",
    "        & (df.vehicle_make != 'STARC')\n",
    "        & (df.vehicle_make != 'BL/BI')\n",
    "        & (df.vehicle_make != 'COLLI')\n",
    "        & (df.vehicle_make != 'UNIFL')\n",
    "        & (df.vehicle_make != 'ORION')\n",
    "        & (df.vehicle_make != 'TSM')\n",
    "        & (df.vehicle_make != 'EASTO')]\n",
    "df = df.groupby('vehicle_make').filter(lambda x: len(x) > 100)\n",
    "\n",
    "makes = {\n",
    "    'FORD': 'Ford',\n",
    "    'TOYOT': 'Toyota',\n",
    "    'HONDA': 'Honda',\n",
    "    'NISSA': 'Nissan',\n",
    "    'CHEVR': 'Chevrolet',\n",
    "    'ME/BE': 'Mercedes-Benz',\n",
    "    'FREUH': 'Fruehauf',\n",
    "    'DODGE': 'Dodge',\n",
    "    'HYUND': 'Hyundai',\n",
    "    'JEEP': 'Jeep',\n",
    "    'LEXUS': 'Lexus',\n",
    "    'INTER': 'International Harvester',\n",
    "    'ACURA': 'Acura',\n",
    "    'INFIN': 'Infiniti',\n",
    "    'SUBAR': 'Subaru',\n",
    "    'VOLKS': 'Volkswagen',\n",
    "    'HIN': 'Hindustan Motors',\n",
    "    'CHRYS': 'Chrystler',\n",
    "    'AUDI': 'Audi',\n",
    "    'ISUZU': 'Isuzu',\n",
    "    'KIA': 'Kia',\n",
    "    'MAZDA': 'Mazda',\n",
    "    'MITSU': 'Mitsubishi',\n",
    "    'ROVER': 'Land Rover',\n",
    "    'CADIL': 'Cadillac',\n",
    "    'LINCO': 'Lincoln',\n",
    "    'VOLVO': 'Volvo',\n",
    "    'WORKH': 'Workhorse',\n",
    "    'KENWO': 'Kenworth',\n",
    "    'BUICK': 'Buick',\n",
    "    'SMART': 'smart',\n",
    "    'PETER': 'Peterbilt',\n",
    "    'MINI': 'Mini',\n",
    "    'PORSC': 'Porsche',\n",
    "    'MERCU': 'Mercury',\n",
    "    'JAGUA': 'Jaguar',\n",
    "    'FIAT': 'Fiat',\n",
    "    'SATUR': 'Saturn',\n",
    "    'PONTI': 'Pontiac',\n",
    "    'UTILI': 'Utility',\n",
    "    'MACK': 'Mack',\n",
    "    'TESLA': 'Tesla',\n",
    "    'SUZUK': 'Suzuki',\n",
    "    'UD': 'UD Trucks',\n",
    "    'MASE': 'Maserati',\n",
    "    'SAAB': 'Saab',\n",
    "    'HYUN': 'Hyundai',\n",
    "    'HUMME': 'Hummer',\n",
    "    'OLDSM': 'Oldsmobile',\n",
    "    'MCI': 'Motor Coach Industries',\n",
    "    'THOMA': 'Thomas Built Busses',\n",
    "    'IC': 'IC Bus',\n",
    "    'YAMAH': 'Yamaha',\n",
    "    'BENTL': 'Bentley',\n",
    "    'VANHO': 'Van Hool Bus',\n",
    "    'SPRI': 'Springdale RVs',\n",
    "    'KAWAS': 'Kawasaki',\n",
    "    'ALFAR': 'Alfa Romeo',\n",
    "    'PLYMO': 'Plymouth',\n",
    "    'HARLE': 'Harley Davidson',\n",
    "    'STERL': 'Sterling',\n",
    "    'VESPA': 'Vespa',\n",
    "    'UPS': 'UPS Truck',\n",
    "    'VPG': 'Vehicle Production Group',\n",
    "    'PREVO': 'Prevost RVs',\n",
    "    'GEO': 'Geo',\n",
    "    'NAVIS': 'Navistar',\n",
    "    'FERRA': 'Ferrari',\n",
    "    'TRIUM': 'Triumph',\n",
    "    'DUCAT': 'Ducati',\n",
    "    'ZENIT': 'Zenith',\n",
    "    'GENES': 'Genesis',\n",
    "    'SCION': 'Scion',\n",
    "    'HINO': 'Hino Motors',\n",
    "    'ROLLS': 'Rolls Royce',\n",
    "    'LAMBO': 'Lamborgini',\n",
    "    'CHECK': 'Checker Motors',\n",
    "    'SETRA': 'Setra Coach',\n",
    "    'ACUR': 'Acura',\n",
    "    'GREAT': 'Great Dane',\n",
    "    'LEXU': 'Lexus',\n",
    "    'SMITH': 'Smith Electric Vehicles',\n",
    "}\n",
    "\n",
    "df['vehicle_make'] = df['vehicle_make'].apply(lambda row: makes.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up violation county\n",
    "counties = {\n",
    "    'NY': 'Manhattan',\n",
    "    'K': 'Brooklyn',\n",
    "    'Q': 'Queens',\n",
    "    'BX': 'Bronx',\n",
    "    'BK': 'Brooklyn',\n",
    "    'QN': 'Queens',\n",
    "    'R': 'Staten Island',\n",
    "    'ST': 'Staten Island',\n",
    "    'MN': 'Manhattan',\n",
    "    'QUEEN': 'Queens',\n",
    "}\n",
    "df['violation_county'] = df['violation_county'].apply(lambda row: counties.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up registration state\n",
    "df = df[pd.notnull(df.registration_state) & (df.registration_state != '99')]\n",
    "state = {\n",
    "    'GV': 'U.S. Government',\n",
    "    'DP': 'U.S. Department of State',\n",
    "}\n",
    "df['registration_state'] = df['registration_state'].apply(lambda row: state.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df.plate_type) & (df.plate_type != '999')]\n",
    "df = df.groupby('plate_type').filter(lambda x: len(x) > 100)\n",
    "plate_types = {\n",
    "    'PAS': 'Passenger',\n",
    "    'COM': 'Commercial',\n",
    "    'OMT': 'Taxi Omnibus',\n",
    "    'OMS': 'Special Omnibus Rentals',\n",
    "    'SRF': 'Special Passenger',\n",
    "    'APP': 'Apportioned',\n",
    "    'TRC': 'Tractor',\n",
    "    'ORG': 'Organizational',\n",
    "    'OMR': 'Omnibus',\n",
    "    'MED': 'Medical Doctor',\n",
    "    'SPO': 'Sports Passenger',\n",
    "    'OML': 'Livery Omnibus',\n",
    "    'PSD': 'Political Subdivision',\n",
    "    'SCL': 'School Car',\n",
    "    'IRP': 'International Reg Plan',\n",
    "    'TOW': 'Tow Truck',\n",
    "    'MOT': 'Motorcycle',\n",
    "    'RGL': 'Regional',\n",
    "    'VAS': 'Volunteer Ambulance Services',\n",
    "    'ITP': 'In Transit Permit',\n",
    "    'SRN': 'Special Passenger Judges/Officials',\n",
    "    'HIS': 'Historical',\n",
    "    'TRA': 'Transporter',\n",
    "    'CHC': 'Household Carrier Commercial',\n",
    "    'STA': 'State Agencies',\n",
    "    'AGR': 'Agricultural',\n",
    "    'AMB': 'Ambulance',\n",
    "    'PHS': 'Pearl Harbor Survivors',\n",
    "    'AYG': 'Army National Guard',\n",
    "    'RGC': 'Regional Commercial',\n",
    "    'ORC': 'Organizational Commercial',\n",
    "    'TRL': 'Regular Trailer',\n",
    "    'HAM': 'HAM Operator',\n",
    "    'DLR': 'Dealer',\n",
    "}\n",
    "df['plate_type'] = df['plate_type'].apply(lambda row: plate_types.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up issue date, get rid of dates not in 2019 fiscal year\n",
    "# (includes 2018 and 2019 issue dates)\n",
    "df.issue_date = pd.to_datetime(df['issue_date'], errors='coerce')\n",
    "df = df[df.issue_date.dt.year.isin([2018, 2019])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up vehicle body type, get rid of null or unknown\n",
    "# body types, and the least popular ones.\n",
    "df = df[pd.notnull(df.vehicle_body_type) \n",
    "        & (df.vehicle_body_type != 'OLNE')\n",
    "        & (df.vehicle_body_type != 'LL')\n",
    "        & (df.vehicle_body_type != 'APUR')\n",
    "        & (df.vehicle_body_type != 'CW')\n",
    "        & (df.vehicle_body_type != 'O')\n",
    "        & (df.vehicle_body_type != 'EP')\n",
    "        & (df.vehicle_body_type != 'OM')]\n",
    "df = df.groupby('vehicle_body_type').filter(lambda x: len(x) > 100)\n",
    "body_types = {\n",
    "    'SUBN': 'Suburban',\n",
    "    '4DSD': '4 Door Sedan',\n",
    "    'VAN': 'Van',\n",
    "    'DELV': 'Delivery',\n",
    "    'PICK': 'Pickup Truck',\n",
    "    '2DSD': '2 Door Sedan',\n",
    "    'SDN': 'Sedan',\n",
    "    'REFG': 'Refridgerated',\n",
    "    'UTIL': 'Utility',\n",
    "    'TAXI': 'Taxi',\n",
    "    '4 DR': '4 Door',\n",
    "    '4D': '4 Door',\n",
    "    'TRAC': 'Tractor',\n",
    "    'CONV': 'Convertible',\n",
    "    'WAGO': 'Wagon',\n",
    "    'BUS': 'Bus',\n",
    "    'FLAT': 'Flatbed Truck',\n",
    "    'P-U': 'Pickup Truck',\n",
    "    'DUMP': 'Dump Truck',\n",
    "    'UT': 'Utility',\n",
    "    'MCY': 'Motorcycle',\n",
    "    'TRK': 'Truck',\n",
    "    '4W': '4 Door Wagon',\n",
    "    'TOW': 'Tow Truck',\n",
    "    'PKUP': 'Pickup Truck',\n",
    "    '4S': '4 Door Sedan',\n",
    "    'SU': 'Sport Utility Vehicle',\n",
    "    'STAK': 'Stake Truck',\n",
    "    '2 DR': '2 Door',\n",
    "    'MP': 'Moped',\n",
    "    'VN': 'Van',\n",
    "    'TANK': 'Tank Truck',\n",
    "    'SW': 'Station Wagon',\n",
    "    'FOUR': '4 Door',\n",
    "    'SEDN': 'Sedan',\n",
    "    'TK': 'Truck',\n",
    "    '2D': '2 Door',\n",
    "    'SD': 'Sedan',\n",
    "    'PK': 'Pickup Truck',\n",
    "    'SV': 'Sports Van',\n",
    "    '4H': '4 Door Hatchback',\n",
    "    'TR/C': 'Truck Crane',\n",
    "    'CON': 'Convertible',\n",
    "    'TRUC': 'Truck',\n",
    "    'LIM': 'Limousine',\n",
    "    'CP': 'Coupe',\n",
    "    'SEDA': 'Sedan',\n",
    "    '4DOO': '4 Door',\n",
    "    '5D': '5 Door',\n",
    "    'SWT': 'Small-Wheel Truck',\n",
    "    'CV': 'Convertible',\n",
    "    'H/WH': 'Motorhome',\n",
    "    'CMIX': 'Cement Mixer',\n",
    "    '4DSE': '4 Door Sedan',\n",
    "    'TWOD': '2 Door',\n",
    "    'TRL': 'Trailer',\n",
    "    'MC': 'Motorcycle',\n",
    "    'REF': 'Refridgerated',\n",
    "    'TT': 'Tractor Trailer',\n",
    "    'TRC': 'Tractor',\n",
    "    'TRLR': 'Trailer',\n",
    "    'BOAT': 'Boat Trailer',\n",
    "    'ES': 'Station Wagon',\n",
    "    'TRAI': 'Trailer',\n",
    "    'TR': 'Truck',\n",
    "    '2S': '2 Door Sedan',\n",
    "    'HRSE': 'Hearse',\n",
    "    'TLR': 'Trailer',\n",
    "    'SPOR': 'Sports Car',\n",
    "    'SUV': 'SUV',\n",
    "    'MOT': 'Motorcycle',\n",
    "    '2H': '2 Door Hatchback',\n",
    "    'SUBU': 'Suburban',\n",
    "    'TRT': 'Tractor Trailer',\n",
    "    'LIMO': 'Limousine',\n",
    "}\n",
    "df['vehicle_body_type'] = df['vehicle_body_type'].apply(lambda row: body_types.get(row, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each street can be encoded with a 5-digit street code\n",
    "# Each ticket has 3 street codes, because street code 1 \n",
    "# denotes the \"on\" street, while street codes 2 & 3\n",
    "# denote the \"cross\" steets. For example, Lexington Ave\n",
    "# between E 42nd and E 45th is a location, where the \n",
    "# car was parked on Lexington Ave, between E 42nd and E 45th streets.\n",
    "# See below link for more detail:\n",
    "# https://nycplanning.github.io/Geosupport-UPG/chapters/chapterVII/section03/\n",
    "df = df[(df.street_code1 != 0) & (pd.notnull(df.street_code1))\n",
    "   & (df.street_code2 != 0) & (pd.notnull(df.street_code2))\n",
    "   & (df.street_code3 != 0) & (pd.notnull(df.street_code3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.vehicle_expiration_date != 0) & (df.vehicle_expiration_date != 88880088)]\n",
    "df.vehicle_expiration_date = pd.to_datetime(df['vehicle_expiration_date'], format='%Y%m%d',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up violation codes. \n",
    "# 1-99 are valid codes.\n",
    "df = df[(df.violation_code > 0) & (df.violation_code < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up violation & issuer precincts, \n",
    "# get rid of invalid precinct numbers\n",
    "valid_precincts = [1, 5, 6, 7, 9, 10, 13, 14, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 30, \n",
    "                   32, 33, 34, 40, 41, 42, 43, 44, 45, 46,47, 48, 49, 50, 52, 60, 61, \n",
    "                   62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 83, \n",
    "                   84, 88, 90, 94, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, \n",
    "                   110, 111, 112, 113, 114, 115, 120, 121, 122, 123]\n",
    "df = df[df.violation_precinct.isin(valid_precincts)]\n",
    "df = df[df.issuer_precinct.isin(valid_precincts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Clean up violation time by removing\n",
    "# NaNs and restricting rows to only those that\n",
    "# match the regex pattern given. This allows\n",
    "# us to standardize the time format to a 12-hour\n",
    "# format with \"A\" or \"P\" at the end, denoting AM/PM\n",
    "df = df[(pd.notnull(df.violation_time)) & (df.violation_time.str.contains('(1[012]|0[1-9])[0-5][0-9](A|P)', regex=True, na=False))]\n",
    "df.violation_time = df.violation_time.apply(lambda row: float(row[:-1]) if row[4] == 'A' else float(row[:-1])+1200)\n",
    "df.violation_time = df.violation_time.apply(lambda row: row - 2400 if row / 2400 >= 1 else row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, drop all rows where NaN values exist\n",
    "df = df.dropna()\n",
    "\n",
    "# Reset the index so that the DataFrame is easier to work with\n",
    "df = df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to our poor initial results, we considered dropping some of the least\n",
    "# popular violation codes, to try to reduce the number of classes to predict.\n",
    "\n",
    "# Initially, we tried dropping all violation codes with less than 1,000 instances.\n",
    "# This did not improve our results, so we tried dropping all violation codes with\n",
    "# less than 10,000 instances. This did not improve our results either, so we stopped\n",
    "# the experiment, but felt it would be valuable to leave this code here anyways.\n",
    "\n",
    "# good_vcodes = list(df.violation_code.value_counts().head(29).index)\n",
    "# df_clean_vcodes = df[df.violation_code.isin(good_vcodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to sample of 100K for training\n",
    "data = df.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and target\n",
    "# Dropping street name because we will use it as a reference\n",
    "# Rather than a feature for training\n",
    "features = data.drop(columns=[\"violation_code\", \"street_name\"])\n",
    "target = data.violation_code\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "# Encode and scale features\n",
    "encoded_columns = ['registration_state', 'plate_type', 'vehicle_body_type', 'vehicle_make', 'issuing_agency', 'violation_county', 'vehicle_color']\n",
    "categories = [features[column].unique() for column in encoded_columns]\n",
    "encoder = OrdinalEncoder(categories=categories).fit(X_train[encoded_columns])\n",
    "\n",
    "X_train_enc = X_train.copy()\n",
    "X_test_enc = X_test.copy()\n",
    "X_train_enc[encoded_columns] = encoder.transform(X_train[encoded_columns])\n",
    "X_test_enc[encoded_columns] = encoder.transform(X_test[encoded_columns])\n",
    "\n",
    "# Encode Datetime\n",
    "datetime_columns = ['issue_date', 'vehicle_expiration_date']\n",
    "X_train_enc[datetime_columns] = X_train_enc[datetime_columns].astype(int)\n",
    "X_test_enc[datetime_columns] = X_test_enc[datetime_columns].astype(int)\n",
    "\n",
    "X_train, X_test = X_train_enc.to_numpy(), X_test_enc.to_numpy()\n",
    "\n",
    "# Scale\n",
    "# scaler = StandardScaler().fit(X_train_enc)\n",
    "# X_train_scaled = scaler.transform(X_train_enc)\n",
    "# X_test_scaled = scaler.transform(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for outliers\n",
    "iforest = IsolationForest().fit(X_train)\n",
    "train_outliers = iforest.predict(X_train)\n",
    "test_outliers = iforest.predict(X_test)\n",
    "\n",
    "train_non_outliers = train_outliers != -1\n",
    "test_non_outliers = test_outliers != -1\n",
    "\n",
    "X_train, y_train = X_train[train_non_outliers, :], y_train[train_non_outliers]\n",
    "X_test, y_test = X_test[test_non_outliers, :], y_test[test_non_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57,)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21706, 59)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics(y_train, y_pred_train, y_test, y_pred_test, classifier_name):\n",
    "    '''Prints classification metrics for the given classifier_name\n",
    "       Input: y_true and y_predicted for both training and testing, as well as classifier name as a string\n",
    "       Output: None, prints report of accuracy metrics as well as classification report'''\n",
    "    print(f\"{classifier_name}:\")\n",
    "    print(\"\\tTraining:\")\n",
    "    print(\"\\t\\tAccuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"\\t\\tError:\", 1-accuracy_score(y_train, y_pred_train))\n",
    "    print(\"\\t\\tClassification Report:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(\"\\tTesting:\")\n",
    "    print(\"\\t\\tAccuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "    print(\"\\t\\tError:\", 1-accuracy_score(y_test, y_pred_test))\n",
    "    print(\"\\t\\tClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(\"\\t\\tMultilabel Confusion Matrix:\")\n",
    "    print(multilabel_confusion_matrix(y_test, y_pred_test, labels=sorted(pd.Series(y_test).unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier:\n",
      "\tTraining:\n",
      "\t\tAccuracy: 0.3995963055844394\n",
      "\t\tError: 0.6004036944155606\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.17      0.52      0.25        21\n",
      "          10       0.20      0.58      0.29       366\n",
      "          11       0.16      0.43      0.24        65\n",
      "          13       0.21      0.56      0.31       201\n",
      "          14       0.27      0.59      0.37      4998\n",
      "          16       0.24      0.36      0.29      2316\n",
      "          17       0.21      0.23      0.22       853\n",
      "          18       0.21      0.22      0.21       290\n",
      "          19       0.24      0.26      0.25      1577\n",
      "          20       0.33      0.40      0.36      5782\n",
      "          21       0.46      0.61      0.53     12705\n",
      "          22       0.22      0.05      0.08        43\n",
      "          23       0.20      0.09      0.13        11\n",
      "          24       0.00      0.00      0.00        59\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        13\n",
      "          31       0.34      0.10      0.15      1165\n",
      "          35       0.00      0.00      0.00        15\n",
      "          37       0.39      0.20      0.26      2276\n",
      "          38       0.47      0.42      0.44     10378\n",
      "          39       0.00      0.00      0.00        36\n",
      "          40       0.42      0.14      0.22      3382\n",
      "          42       0.36      0.06      0.10       271\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.42      0.19      0.26      3619\n",
      "          47       0.39      0.11      0.17       638\n",
      "          48       0.46      0.04      0.08       425\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00        22\n",
      "          51       0.48      0.02      0.05       404\n",
      "          53       0.46      0.03      0.05       218\n",
      "          54       0.00      0.00      0.00        42\n",
      "          56       0.00      0.00      0.00         4\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       0.00      0.00      0.00        42\n",
      "          61       0.00      0.00      0.00        55\n",
      "          62       0.00      0.00      0.00        11\n",
      "          64       0.00      0.00      0.00        50\n",
      "          67       0.00      0.00      0.00         5\n",
      "          68       0.00      0.00      0.00       160\n",
      "          69       0.40      0.23      0.29      1752\n",
      "          70       0.76      0.91      0.83      2981\n",
      "          71       0.50      0.32      0.39      5854\n",
      "          72       0.57      0.02      0.05       164\n",
      "          73       0.00      0.00      0.00        28\n",
      "          74       0.46      0.05      0.10       969\n",
      "          75       0.00      0.00      0.00       110\n",
      "          77       0.00      0.00      0.00         3\n",
      "          78       0.26      0.02      0.04       259\n",
      "          80       0.00      0.00      0.00        10\n",
      "          82       0.55      0.02      0.04       264\n",
      "          83       1.00      0.02      0.05        41\n",
      "          84       0.33      0.05      0.09       203\n",
      "          85       0.00      0.00      0.00        80\n",
      "          89       0.00      0.00      0.00        30\n",
      "          91       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.40     65396\n",
      "   macro avg       0.21      0.13      0.12     65396\n",
      "weighted avg       0.41      0.40      0.38     65396\n",
      "\n",
      "\tTesting:\n",
      "\t\tAccuracy: 0.17631069750299455\n",
      "\t\tError: 0.8236893024970054\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         4\n",
      "          10       0.01      0.02      0.01       129\n",
      "          11       0.00      0.00      0.00        24\n",
      "          13       0.01      0.03      0.02        69\n",
      "          14       0.08      0.19      0.11      1612\n",
      "          16       0.05      0.07      0.06       746\n",
      "          17       0.01      0.02      0.02       312\n",
      "          18       0.03      0.03      0.03       117\n",
      "          19       0.04      0.04      0.04       558\n",
      "          20       0.11      0.13      0.12      1931\n",
      "          21       0.25      0.31      0.28      4246\n",
      "          22       0.00      0.00      0.00        13\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00        15\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         5\n",
      "          31       0.02      0.00      0.01       425\n",
      "          35       0.00      0.00      0.00         1\n",
      "          37       0.08      0.04      0.05       740\n",
      "          38       0.19      0.17      0.18      3507\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.06      0.02      0.03      1124\n",
      "          42       0.00      0.00      0.00        77\n",
      "          45       0.00      0.00      0.00         5\n",
      "          46       0.07      0.04      0.05      1183\n",
      "          47       0.02      0.01      0.01       200\n",
      "          48       0.06      0.01      0.01       161\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00       122\n",
      "          53       0.00      0.00      0.00        55\n",
      "          54       0.00      0.00      0.00        13\n",
      "          56       0.00      0.00      0.00         2\n",
      "          60       0.00      0.00      0.00         6\n",
      "          61       0.00      0.00      0.00        15\n",
      "          62       0.00      0.00      0.00         5\n",
      "          64       0.00      0.00      0.00        13\n",
      "          67       0.00      0.00      0.00         4\n",
      "          68       0.00      0.00      0.00        54\n",
      "          69       0.04      0.03      0.03       520\n",
      "          70       0.73      0.90      0.81      1002\n",
      "          71       0.20      0.13      0.16      1885\n",
      "          72       0.00      0.00      0.00        54\n",
      "          73       0.00      0.00      0.00         5\n",
      "          74       0.00      0.00      0.00       344\n",
      "          75       0.00      0.00      0.00        33\n",
      "          77       0.00      0.00      0.00         3\n",
      "          78       0.00      0.00      0.00        97\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         4\n",
      "          82       0.00      0.00      0.00        89\n",
      "          83       0.00      0.00      0.00        11\n",
      "          84       0.00      0.00      0.00        70\n",
      "          85       0.00      0.00      0.00        32\n",
      "          89       0.00      0.00      0.00         6\n",
      "          98       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.18     21706\n",
      "   macro avg       0.04      0.04      0.04     21706\n",
      "weighted avg       0.16      0.18      0.16     21706\n",
      "\n",
      "\t\tMultilabel Confusion Matrix:\n",
      "[[[21705     0]\n",
      "  [    1     0]]\n",
      "\n",
      " [[21673    29]\n",
      "  [    4     0]]\n",
      "\n",
      " [[21248   329]\n",
      "  [  126     3]]\n",
      "\n",
      " [[21624    58]\n",
      "  [   24     0]]\n",
      "\n",
      " [[21482   155]\n",
      "  [   67     2]]\n",
      "\n",
      " [[16628  3466]\n",
      "  [ 1310   302]]\n",
      "\n",
      " [[19833  1127]\n",
      "  [  691    55]]\n",
      "\n",
      " [[21060   334]\n",
      "  [  307     5]]\n",
      "\n",
      " [[21473   116]\n",
      "  [  114     3]]\n",
      "\n",
      " [[20636   512]\n",
      "  [  538    20]]\n",
      "\n",
      " [[17724  2051]\n",
      "  [ 1671   260]]\n",
      "\n",
      " [[13417  4043]\n",
      "  [ 2914  1332]]\n",
      "\n",
      " [[21691     2]\n",
      "  [   13     0]]\n",
      "\n",
      " [[21701     2]\n",
      "  [    3     0]]\n",
      "\n",
      " [[21691     0]\n",
      "  [   15     0]]\n",
      "\n",
      " [[21704     0]\n",
      "  [    2     0]]\n",
      "\n",
      " [[21700     1]\n",
      "  [    5     0]]\n",
      "\n",
      " [[21172   109]\n",
      "  [  423     2]]\n",
      "\n",
      " [[21705     0]\n",
      "  [    1     0]]\n",
      "\n",
      " [[20636   330]\n",
      "  [  710    30]]\n",
      "\n",
      " [[15634  2565]\n",
      "  [ 2921   586]]\n",
      "\n",
      " [[21695     0]\n",
      "  [   11     0]]\n",
      "\n",
      " [[20218   364]\n",
      "  [ 1102    22]]\n",
      "\n",
      " [[21614    15]\n",
      "  [   77     0]]\n",
      "\n",
      " [[21701     0]\n",
      "  [    5     0]]\n",
      "\n",
      " [[19993   530]\n",
      "  [ 1141    42]]\n",
      "\n",
      " [[21444    62]\n",
      "  [  199     1]]\n",
      "\n",
      " [[21529    16]\n",
      "  [  160     1]]\n",
      "\n",
      " [[21704     0]\n",
      "  [    2     0]]\n",
      "\n",
      " [[21693     0]\n",
      "  [   13     0]]\n",
      "\n",
      " [[21577     7]\n",
      "  [  122     0]]\n",
      "\n",
      " [[21646     5]\n",
      "  [   55     0]]\n",
      "\n",
      " [[21693     0]\n",
      "  [   13     0]]\n",
      "\n",
      " [[21704     0]\n",
      "  [    2     0]]\n",
      "\n",
      " [[21700     0]\n",
      "  [    6     0]]\n",
      "\n",
      " [[21691     0]\n",
      "  [   15     0]]\n",
      "\n",
      " [[21701     0]\n",
      "  [    5     0]]\n",
      "\n",
      " [[21693     0]\n",
      "  [   13     0]]\n",
      "\n",
      " [[21702     0]\n",
      "  [    4     0]]\n",
      "\n",
      " [[21652     0]\n",
      "  [   54     0]]\n",
      "\n",
      " [[20888   298]\n",
      "  [  506    14]]\n",
      "\n",
      " [[20373   331]\n",
      "  [  100   902]]\n",
      "\n",
      " [[18861   960]\n",
      "  [ 1640   245]]\n",
      "\n",
      " [[21649     3]\n",
      "  [   54     0]]\n",
      "\n",
      " [[21701     0]\n",
      "  [    5     0]]\n",
      "\n",
      " [[21320    42]\n",
      "  [  344     0]]\n",
      "\n",
      " [[21672     1]\n",
      "  [   33     0]]\n",
      "\n",
      " [[21703     0]\n",
      "  [    3     0]]\n",
      "\n",
      " [[21605     4]\n",
      "  [   97     0]]\n",
      "\n",
      " [[21705     0]\n",
      "  [    1     0]]\n",
      "\n",
      " [[21702     0]\n",
      "  [    4     0]]\n",
      "\n",
      " [[21612     5]\n",
      "  [   89     0]]\n",
      "\n",
      " [[21694     1]\n",
      "  [   11     0]]\n",
      "\n",
      " [[21630     6]\n",
      "  [   70     0]]\n",
      "\n",
      " [[21674     0]\n",
      "  [   32     0]]\n",
      "\n",
      " [[21700     0]\n",
      "  [    6     0]]\n",
      "\n",
      " [[21681     0]\n",
      "  [   25     0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  sample_weight=sample_weight)\n",
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  sample_weight=sample_weight)\n",
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  sample_weight=sample_weight)\n",
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b160f448c90>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b160f61f2d0>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.05)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC for all classifiers')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b160f608490>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train, test, and evaluate kNN\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = knn.predict(X_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "metrics(y_train, y_pred_train, y_test, y_pred_test, 'kNN Classifier')\n",
    "\n",
    "y_score = knn.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(pd.Series(y_train).unique())):\n",
    "    fpr[i], tpr[i], _ = roc_curve(label_binarize(y_test, classes=pd.Series(y_train).unique())[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label_binarize(y_test, classes=pd.Series(y_train).unique()).ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for all classifiers')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "\tTraining:\n",
      "\t\tAccuracy: 0.5120630082834166\n",
      "\t\tError: 0.48793699171658345\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         1\n",
      "           8       0.41      0.37      0.39        19\n",
      "          10       0.65      0.34      0.44       359\n",
      "          11       0.83      0.14      0.25        69\n",
      "          13       0.64      0.47      0.54       204\n",
      "          14       0.52      0.33      0.40      4952\n",
      "          16       0.52      0.27      0.36      2316\n",
      "          17       0.53      0.11      0.18       893\n",
      "          18       0.59      0.30      0.39       321\n",
      "          19       0.50      0.12      0.20      1556\n",
      "          20       0.51      0.40      0.45      5803\n",
      "          21       0.58      0.90      0.71     12991\n",
      "          22       1.00      0.07      0.13        43\n",
      "          23       0.60      0.27      0.37        11\n",
      "          24       1.00      0.06      0.11        50\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.75      0.27      0.40        11\n",
      "          27       0.00      0.00      0.00        10\n",
      "          31       0.40      0.62      0.48      1166\n",
      "          35       1.00      0.27      0.43        11\n",
      "          37       0.72      0.46      0.56      2699\n",
      "          38       0.38      0.67      0.48     10464\n",
      "          39       1.00      0.03      0.06        33\n",
      "          40       0.47      0.32      0.38      3392\n",
      "          42       0.91      0.66      0.77       378\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       0.55      0.33      0.41      3568\n",
      "          47       0.67      0.60      0.63       631\n",
      "          48       0.57      0.14      0.22       437\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00        24\n",
      "          51       0.70      0.03      0.06       422\n",
      "          53       0.79      0.15      0.25       209\n",
      "          54       0.67      0.51      0.58        39\n",
      "          56       0.00      0.00      0.00         7\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       1.00      0.08      0.14        39\n",
      "          61       1.00      0.07      0.12        46\n",
      "          62       1.00      0.07      0.12        15\n",
      "          64       0.89      0.16      0.27        50\n",
      "          67       0.00      0.00      0.00         3\n",
      "          68       0.40      0.12      0.19       165\n",
      "          69       0.51      0.77      0.61      1666\n",
      "          70       0.81      0.72      0.76      3059\n",
      "          71       0.42      0.17      0.24      5883\n",
      "          72       1.00      0.03      0.07       173\n",
      "          73       0.00      0.00      0.00        28\n",
      "          74       0.85      0.05      0.10      1001\n",
      "          75       1.00      0.07      0.14       107\n",
      "          77       0.00      0.00      0.00         6\n",
      "          78       0.93      0.89      0.91       266\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         8\n",
      "          82       0.83      0.15      0.25       263\n",
      "          83       0.00      0.00      0.00        38\n",
      "          84       0.71      0.30      0.42       186\n",
      "          85       0.92      0.81      0.86        86\n",
      "          89       0.79      0.42      0.55        26\n",
      "          91       0.00      0.00      0.00         1\n",
      "          98       1.00      0.03      0.06        61\n",
      "\n",
      "    accuracy                           0.51     66277\n",
      "   macro avg       0.53      0.23      0.27     66277\n",
      "weighted avg       0.54      0.51      0.48     66277\n",
      "\n",
      "\tTesting:\n",
      "\t\tAccuracy: 0.41125815808556926\n",
      "\t\tError: 0.5887418419144308\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.00      0.00      0.00         6\n",
      "          10       0.20      0.11      0.14       123\n",
      "          11       0.00      0.00      0.00        21\n",
      "          13       0.29      0.20      0.23        66\n",
      "          14       0.28      0.18      0.22      1659\n",
      "          16       0.32      0.17      0.22       785\n",
      "          17       0.14      0.03      0.05       281\n",
      "          18       0.18      0.13      0.15        79\n",
      "          19       0.08      0.02      0.03       528\n",
      "          20       0.37      0.30      0.33      1943\n",
      "          21       0.55      0.85      0.66      4314\n",
      "          22       0.00      0.00      0.00        13\n",
      "          23       0.00      0.00      0.00         4\n",
      "          24       0.00      0.00      0.00        21\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         7\n",
      "          31       0.32      0.46      0.38       412\n",
      "          35       0.00      0.00      0.00         5\n",
      "          37       0.60      0.42      0.49       777\n",
      "          38       0.33      0.58      0.42      3547\n",
      "          39       0.00      0.00      0.00        15\n",
      "          40       0.33      0.21      0.25      1183\n",
      "          42       0.69      0.49      0.58       128\n",
      "          46       0.34      0.19      0.25      1236\n",
      "          47       0.32      0.30      0.31       200\n",
      "          48       0.15      0.04      0.06       147\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         6\n",
      "          51       0.00      0.00      0.00       106\n",
      "          53       0.24      0.06      0.10        64\n",
      "          54       0.18      0.19      0.18        16\n",
      "          56       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00        10\n",
      "          61       0.00      0.00      0.00        20\n",
      "          62       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00        13\n",
      "          68       0.05      0.02      0.03        53\n",
      "          69       0.42      0.62      0.50       592\n",
      "          70       0.64      0.57      0.60       981\n",
      "          71       0.24      0.10      0.14      1979\n",
      "          72       0.00      0.00      0.00        49\n",
      "          73       0.00      0.00      0.00         6\n",
      "          74       0.00      0.00      0.00       331\n",
      "          75       0.00      0.00      0.00        42\n",
      "          78       0.60      0.67      0.63        60\n",
      "          80       0.00      0.00      0.00         7\n",
      "          82       0.07      0.01      0.02        75\n",
      "          83       0.00      0.00      0.00        13\n",
      "          84       0.13      0.05      0.07        81\n",
      "          85       0.44      0.38      0.41        21\n",
      "          89       0.33      0.10      0.15        10\n",
      "          98       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.41     22064\n",
      "   macro avg       0.17      0.14      0.15     22064\n",
      "weighted avg       0.37      0.41      0.37     22064\n",
      "\n",
      "\t\tMultilabel Confusion Matrix:\n",
      "[[[22054     4]\n",
      "  [    6     0]]\n",
      "\n",
      " [[21889    52]\n",
      "  [  110    13]]\n",
      "\n",
      " [[22042     1]\n",
      "  [   21     0]]\n",
      "\n",
      " [[21966    32]\n",
      "  [   53    13]]\n",
      "\n",
      " [[19610   795]\n",
      "  [ 1355   304]]\n",
      "\n",
      " [[20994   285]\n",
      "  [  653   132]]\n",
      "\n",
      " [[21727    56]\n",
      "  [  272     9]]\n",
      "\n",
      " [[21940    45]\n",
      "  [   69    10]]\n",
      "\n",
      " [[21418   118]\n",
      "  [  518    10]]\n",
      "\n",
      " [[19150   971]\n",
      "  [ 1369   574]]\n",
      "\n",
      " [[14704  3046]\n",
      "  [  663  3651]]\n",
      "\n",
      " [[22050     1]\n",
      "  [   13     0]]\n",
      "\n",
      " [[22060     0]\n",
      "  [    4     0]]\n",
      "\n",
      " [[22042     1]\n",
      "  [   21     0]]\n",
      "\n",
      " [[22057     0]\n",
      "  [    7     0]]\n",
      "\n",
      " [[21255   397]\n",
      "  [  221   191]]\n",
      "\n",
      " [[22057     2]\n",
      "  [    5     0]]\n",
      "\n",
      " [[21075   212]\n",
      "  [  453   324]]\n",
      "\n",
      " [[14272  4245]\n",
      "  [ 1494  2053]]\n",
      "\n",
      " [[22049     0]\n",
      "  [   15     0]]\n",
      "\n",
      " [[20374   507]\n",
      "  [  938   245]]\n",
      "\n",
      " [[21908    28]\n",
      "  [   65    63]]\n",
      "\n",
      " [[20374   454]\n",
      "  [ 1000   236]]\n",
      "\n",
      " [[21739   125]\n",
      "  [  140    60]]\n",
      "\n",
      " [[21884    33]\n",
      "  [  141     6]]\n",
      "\n",
      " [[22062     0]\n",
      "  [    2     0]]\n",
      "\n",
      " [[22058     0]\n",
      "  [    6     0]]\n",
      "\n",
      " [[21953     5]\n",
      "  [  106     0]]\n",
      "\n",
      " [[21987    13]\n",
      "  [   60     4]]\n",
      "\n",
      " [[22034    14]\n",
      "  [   13     3]]\n",
      "\n",
      " [[22063     0]\n",
      "  [    1     0]]\n",
      "\n",
      " [[22052     2]\n",
      "  [   10     0]]\n",
      "\n",
      " [[22043     1]\n",
      "  [   20     0]]\n",
      "\n",
      " [[22062     0]\n",
      "  [    2     0]]\n",
      "\n",
      " [[22050     1]\n",
      "  [   13     0]]\n",
      "\n",
      " [[21991    20]\n",
      "  [   52     1]]\n",
      "\n",
      " [[20966   506]\n",
      "  [  222   370]]\n",
      "\n",
      " [[20770   313]\n",
      "  [  422   559]]\n",
      "\n",
      " [[19486   599]\n",
      "  [ 1790   189]]\n",
      "\n",
      " [[22012     3]\n",
      "  [   49     0]]\n",
      "\n",
      " [[22058     0]\n",
      "  [    6     0]]\n",
      "\n",
      " [[21716    17]\n",
      "  [  331     0]]\n",
      "\n",
      " [[22017     5]\n",
      "  [   42     0]]\n",
      "\n",
      " [[21977    27]\n",
      "  [   20    40]]\n",
      "\n",
      " [[22057     0]\n",
      "  [    7     0]]\n",
      "\n",
      " [[21976    13]\n",
      "  [   74     1]]\n",
      "\n",
      " [[22051     0]\n",
      "  [   13     0]]\n",
      "\n",
      " [[21956    27]\n",
      "  [   77     4]]\n",
      "\n",
      " [[22033    10]\n",
      "  [   13     8]]\n",
      "\n",
      " [[22052     2]\n",
      "  [    9     1]]\n",
      "\n",
      " [[22039     1]\n",
      "  [   24     0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train, test, and evaluate Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=13).fit(X_train, y_train)\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred_test = tree.predict(X_test)\n",
    "metrics(y_train, y_pred_train, y_test, y_pred_test, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "\tTraining:\n",
      "\t\tAccuracy: 0.9999105918817429\n",
      "\t\tError: 8.940811825708384e-05\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00        21\n",
      "          10       1.00      1.00      1.00       369\n",
      "          11       1.00      1.00      1.00        72\n",
      "          13       1.00      1.00      1.00       208\n",
      "          14       1.00      1.00      1.00      4994\n",
      "          16       1.00      1.00      1.00      2363\n",
      "          17       1.00      1.00      1.00       883\n",
      "          18       1.00      1.00      1.00       304\n",
      "          19       1.00      1.00      1.00      1592\n",
      "          20       1.00      1.00      1.00      5861\n",
      "          21       1.00      1.00      1.00     13015\n",
      "          22       1.00      1.00      1.00        47\n",
      "          23       1.00      1.00      1.00        13\n",
      "          24       1.00      1.00      1.00        51\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         9\n",
      "          27       1.00      1.00      1.00        13\n",
      "          31       1.00      1.00      1.00      1216\n",
      "          35       1.00      1.00      1.00        12\n",
      "          37       1.00      1.00      1.00      3083\n",
      "          38       1.00      1.00      1.00     10410\n",
      "          39       1.00      1.00      1.00        34\n",
      "          40       1.00      1.00      1.00      3387\n",
      "          41       1.00      1.00      1.00         1\n",
      "          42       1.00      1.00      1.00       419\n",
      "          45       1.00      1.00      1.00         8\n",
      "          46       1.00      1.00      1.00      3702\n",
      "          47       1.00      1.00      1.00       652\n",
      "          48       1.00      1.00      1.00       422\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00        32\n",
      "          51       1.00      1.00      1.00       380\n",
      "          53       1.00      1.00      1.00       216\n",
      "          54       1.00      1.00      1.00        44\n",
      "          56       1.00      1.00      1.00         8\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       1.00      1.00      1.00        39\n",
      "          61       1.00      1.00      1.00        53\n",
      "          62       1.00      1.00      1.00        11\n",
      "          64       1.00      1.00      1.00        45\n",
      "          67       1.00      1.00      1.00         3\n",
      "          68       1.00      1.00      1.00       167\n",
      "          69       1.00      1.00      1.00      1681\n",
      "          70       1.00      1.00      1.00      3048\n",
      "          71       1.00      1.00      1.00      5932\n",
      "          72       1.00      1.00      1.00       166\n",
      "          73       1.00      1.00      1.00        27\n",
      "          74       1.00      1.00      1.00       998\n",
      "          75       1.00      1.00      1.00        99\n",
      "          77       1.00      0.75      0.86         4\n",
      "          78       1.00      1.00      1.00       257\n",
      "          80       1.00      1.00      1.00        10\n",
      "          82       1.00      1.00      1.00       267\n",
      "          83       1.00      1.00      1.00        42\n",
      "          84       1.00      1.00      1.00       199\n",
      "          85       1.00      1.00      1.00        89\n",
      "          89       1.00      1.00      1.00        26\n",
      "          91       1.00      1.00      1.00         1\n",
      "          98       1.00      1.00      1.00        97\n",
      "\n",
      "    accuracy                           1.00     67108\n",
      "   macro avg       1.00      1.00      1.00     67108\n",
      "weighted avg       1.00      1.00      1.00     67108\n",
      "\n",
      "\tTesting:\n",
      "\t\tAccuracy: 0.4804206757663907\n",
      "\t\tError: 0.5195793242336093\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.00      0.00      0.00         4\n",
      "          10       0.41      0.12      0.18       120\n",
      "          11       0.50      0.06      0.11        16\n",
      "          13       0.65      0.43      0.51        61\n",
      "          14       0.37      0.28      0.32      1664\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.48      0.31      0.37       756\n",
      "          17       0.30      0.03      0.06       299\n",
      "          18       0.33      0.13      0.19       104\n",
      "          19       0.28      0.04      0.08       529\n",
      "          20       0.43      0.38      0.41      1926\n",
      "          21       0.56      0.91      0.70      4345\n",
      "          22       0.20      0.10      0.13        10\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00        25\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         2\n",
      "          31       0.45      0.60      0.51       372\n",
      "          35       1.00      0.33      0.50         3\n",
      "          37       0.75      0.56      0.64      1134\n",
      "          38       0.41      0.60      0.49      3554\n",
      "          39       1.00      0.15      0.27        13\n",
      "          40       0.37      0.21      0.27      1168\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.78      0.42      0.55       145\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.37      0.30      0.33      1170\n",
      "          47       0.42      0.50      0.45       206\n",
      "          48       0.29      0.03      0.05       167\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         4\n",
      "          51       0.20      0.01      0.01       149\n",
      "          53       0.36      0.07      0.11        59\n",
      "          54       0.00      0.00      0.00        10\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00        12\n",
      "          61       0.00      0.00      0.00        14\n",
      "          62       0.00      0.00      0.00         5\n",
      "          64       0.33      0.06      0.10        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.69      0.17      0.27        54\n",
      "          69       0.49      0.64      0.56       605\n",
      "          70       0.62      0.70      0.66       981\n",
      "          71       0.31      0.15      0.21      1877\n",
      "          72       0.00      0.00      0.00        52\n",
      "          73       0.00      0.00      0.00         8\n",
      "          74       0.11      0.00      0.01       329\n",
      "          75       0.00      0.00      0.00        48\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.76      0.78      0.77        78\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         4\n",
      "          82       0.20      0.03      0.04        80\n",
      "          83       0.00      0.00      0.00         9\n",
      "          84       0.21      0.07      0.11        69\n",
      "          85       0.62      0.65      0.63        20\n",
      "          89       0.67      0.40      0.50        10\n",
      "          98       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.48     22345\n",
      "   macro avg       0.29      0.18      0.19     22345\n",
      "weighted avg       0.45      0.48      0.44     22345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train, test, and evaluate Random Forest\n",
    "rforest = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred_train = rforest.predict(X_train)\n",
    "y_pred_test = rforest.predict(X_test)\n",
    "metrics(y_train, y_pred_train, y_test, y_pred_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "\tTraining:\n",
      "\t\tAccuracy: 0.6061423377242654\n",
      "\t\tError: 0.3938576622757346\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       1.00      1.00      1.00         1\n",
      "           8       1.00      0.81      0.89        21\n",
      "          10       0.86      0.64      0.74       369\n",
      "          11       1.00      0.64      0.78        72\n",
      "          13       0.99      0.71      0.83       208\n",
      "          14       0.53      0.59      0.56      4994\n",
      "          16       0.68      0.49      0.57      2363\n",
      "          17       0.77      0.37      0.50       883\n",
      "          18       0.93      0.65      0.77       304\n",
      "          19       0.73      0.44      0.55      1592\n",
      "          20       0.56      0.58      0.57      5861\n",
      "          21       0.67      0.69      0.68     13015\n",
      "          22       1.00      0.60      0.75        47\n",
      "          23       1.00      1.00      1.00        13\n",
      "          24       1.00      0.80      0.89        51\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         9\n",
      "          27       1.00      1.00      1.00        13\n",
      "          31       0.73      0.63      0.67      1216\n",
      "          35       1.00      0.92      0.96        12\n",
      "          37       0.77      0.69      0.73      3083\n",
      "          38       0.50      0.63      0.55     10410\n",
      "          39       1.00      0.79      0.89        34\n",
      "          40       0.55      0.50      0.52      3387\n",
      "          41       1.00      1.00      1.00         1\n",
      "          42       0.92      0.80      0.85       419\n",
      "          45       1.00      1.00      1.00         8\n",
      "          46       0.58      0.55      0.56      3702\n",
      "          47       0.82      0.66      0.73       652\n",
      "          48       0.94      0.43      0.59       422\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      0.69      0.81        32\n",
      "          51       0.89      0.38      0.53       380\n",
      "          53       0.98      0.57      0.72       216\n",
      "          54       1.00      0.93      0.96        44\n",
      "          56       1.00      1.00      1.00         8\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       1.00      0.77      0.87        39\n",
      "          61       1.00      0.81      0.90        53\n",
      "          62       1.00      1.00      1.00        11\n",
      "          64       1.00      0.71      0.83        45\n",
      "          67       1.00      1.00      1.00         3\n",
      "          68       0.95      0.59      0.73       167\n",
      "          69       0.69      0.69      0.69      1681\n",
      "          70       0.83      0.68      0.75      3048\n",
      "          71       0.43      0.53      0.48      5932\n",
      "          72       1.00      0.42      0.59       166\n",
      "          73       1.00      0.70      0.83        27\n",
      "          74       0.75      0.37      0.49       998\n",
      "          75       1.00      0.44      0.62        99\n",
      "          77       1.00      0.50      0.67         4\n",
      "          78       1.00      0.99      0.99       257\n",
      "          80       1.00      0.90      0.95        10\n",
      "          82       0.88      0.54      0.67       267\n",
      "          83       1.00      0.74      0.85        42\n",
      "          84       0.93      0.63      0.75       199\n",
      "          85       1.00      0.96      0.98        89\n",
      "          89       1.00      0.69      0.82        26\n",
      "          91       1.00      1.00      1.00         1\n",
      "          98       1.00      0.71      0.83        97\n",
      "\n",
      "    accuracy                           0.61     67108\n",
      "   macro avg       0.90      0.73      0.79     67108\n",
      "weighted avg       0.63      0.61      0.61     67108\n",
      "\n",
      "\tTesting:\n",
      "\t\tAccuracy: 0.3043186395166704\n",
      "\t\tError: 0.6956813604833296\n",
      "\t\tClassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.00      0.00      0.00         4\n",
      "          10       0.14      0.05      0.07       120\n",
      "          11       0.00      0.00      0.00        16\n",
      "          13       0.46      0.10      0.16        61\n",
      "          14       0.17      0.23      0.20      1664\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.19      0.12      0.15       756\n",
      "          17       0.06      0.01      0.02       299\n",
      "          18       0.29      0.04      0.07       104\n",
      "          19       0.06      0.02      0.03       529\n",
      "          20       0.22      0.26      0.24      1926\n",
      "          21       0.48      0.51      0.50      4345\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00        25\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         2\n",
      "          31       0.25      0.20      0.22       372\n",
      "          35       0.00      0.00      0.00         3\n",
      "          37       0.65      0.53      0.59      1134\n",
      "          38       0.28      0.40      0.33      3554\n",
      "          39       0.00      0.00      0.00        13\n",
      "          40       0.17      0.15      0.16      1168\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.61      0.32      0.42       145\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.20      0.19      0.20      1170\n",
      "          47       0.36      0.26      0.31       206\n",
      "          48       0.12      0.01      0.01       167\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         4\n",
      "          51       0.08      0.01      0.01       149\n",
      "          53       0.00      0.00      0.00        59\n",
      "          54       0.00      0.00      0.00        10\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00        12\n",
      "          61       0.00      0.00      0.00        14\n",
      "          62       0.00      0.00      0.00         5\n",
      "          64       0.00      0.00      0.00        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.50      0.06      0.10        54\n",
      "          69       0.33      0.30      0.31       605\n",
      "          70       0.64      0.39      0.49       981\n",
      "          71       0.14      0.20      0.17      1877\n",
      "          72       0.00      0.00      0.00        52\n",
      "          73       0.00      0.00      0.00         8\n",
      "          74       0.08      0.02      0.03       329\n",
      "          75       0.00      0.00      0.00        48\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.82      0.47      0.60        78\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         4\n",
      "          82       0.15      0.03      0.04        80\n",
      "          83       0.00      0.00      0.00         9\n",
      "          84       0.10      0.03      0.04        69\n",
      "          85       1.00      0.45      0.62        20\n",
      "          89       0.00      0.00      0.00        10\n",
      "          98       0.67      0.10      0.17        41\n",
      "\n",
      "    accuracy                           0.30     22345\n",
      "   macro avg       0.16      0.09      0.11     22345\n",
      "weighted avg       0.31      0.30      0.30     22345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosiborod.b/.conda/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define base classifier for AdaBoost.\n",
    "# Decision Tree w/max_depth=13 worked the best so far...\n",
    "\n",
    "# Train, test, and evaluate AdaBoost\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=13)).fit(X_train, y_train)\n",
    "y_pred_train = ada.predict(X_train)\n",
    "y_pred_test = ada.predict(X_test)\n",
    "metrics(y_train, y_pred_train, y_test, y_pred_test, 'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    '''Multilayer perceptron definition. H/T Alina Oprea'''\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"Compiling Model\")\n",
    "    model = Sequential()\n",
    "    # 17 features\n",
    "    model.add(Dense(500, input_dim=17))\n",
    "    model.add(Activation('sigmoid'))\n",
    "#     model.add(Dropout(0.4))\n",
    "    model.add(Dense(250))\n",
    "    model.add(Activation('sigmoid'))\n",
    "#     model.add(Dropout(0.4))\n",
    "    # 100 different output classes\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    rms = RMSprop()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
    "    \n",
    "    print(f\"Model finished in: {time.time() - start_time}\")\n",
    "    return model\n",
    "\n",
    "def run_network(model=None, epochs=20, batch=256):\n",
    "    '''Run the neural network. H/T Alina Oprea'''\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Training model\")\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    print(f\"Training duration: {time.time() - start_time}\")\n",
    "    score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "\n",
    "    print(f\"\\nNetwork's test loss and accuracy duration: {time.time() - start_time}\")\n",
    "    return history\n",
    "\n",
    "def plot_losses(hist):\n",
    "    '''Plot metrics of the neural network. H/T Alina Oprea'''\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model\n",
      "Model finished in: 0.04150843620300293\n",
      "Training model\n",
      "Epoch 1/100\n",
      "255/255 - 1s - loss: 2.7418 - accuracy: 0.1874 - val_loss: 2.7716 - val_accuracy: 0.1572\n",
      "Epoch 2/100\n",
      "255/255 - 1s - loss: 2.6603 - accuracy: 0.2187 - val_loss: 2.6508 - val_accuracy: 0.2339\n",
      "Epoch 3/100\n",
      "255/255 - 1s - loss: 2.6232 - accuracy: 0.2279 - val_loss: 2.6270 - val_accuracy: 0.2339\n",
      "Epoch 4/100\n",
      "255/255 - 1s - loss: 2.6127 - accuracy: 0.2290 - val_loss: 2.6180 - val_accuracy: 0.2339\n",
      "Epoch 5/100\n",
      "255/255 - 1s - loss: 2.6067 - accuracy: 0.2310 - val_loss: 2.6576 - val_accuracy: 0.2281\n",
      "Epoch 6/100\n",
      "255/255 - 1s - loss: 2.6030 - accuracy: 0.2317 - val_loss: 2.6003 - val_accuracy: 0.2339\n",
      "Epoch 7/100\n",
      "255/255 - 1s - loss: 2.6002 - accuracy: 0.2319 - val_loss: 2.6003 - val_accuracy: 0.2339\n",
      "Epoch 8/100\n",
      "255/255 - 1s - loss: 2.5987 - accuracy: 0.2332 - val_loss: 2.6157 - val_accuracy: 0.1959\n",
      "Epoch 9/100\n",
      "255/255 - 1s - loss: 2.5970 - accuracy: 0.2338 - val_loss: 2.6095 - val_accuracy: 0.2339\n",
      "Epoch 10/100\n",
      "255/255 - 1s - loss: 2.5957 - accuracy: 0.2336 - val_loss: 2.6085 - val_accuracy: 0.2339\n",
      "Epoch 11/100\n",
      "255/255 - 1s - loss: 2.5948 - accuracy: 0.2341 - val_loss: 2.5949 - val_accuracy: 0.2339\n",
      "Epoch 12/100\n",
      "255/255 - 1s - loss: 2.5939 - accuracy: 0.2340 - val_loss: 2.5902 - val_accuracy: 0.2339\n",
      "Epoch 13/100\n",
      "255/255 - 1s - loss: 2.5932 - accuracy: 0.2340 - val_loss: 2.6039 - val_accuracy: 0.2339\n",
      "Epoch 14/100\n",
      "255/255 - 1s - loss: 2.5927 - accuracy: 0.2341 - val_loss: 2.5923 - val_accuracy: 0.2339\n",
      "Epoch 15/100\n",
      "255/255 - 1s - loss: 2.5922 - accuracy: 0.2341 - val_loss: 2.5986 - val_accuracy: 0.2339\n",
      "Epoch 16/100\n",
      "255/255 - 1s - loss: 2.5918 - accuracy: 0.2341 - val_loss: 2.6177 - val_accuracy: 0.2339\n",
      "Epoch 17/100\n",
      "255/255 - 1s - loss: 2.5917 - accuracy: 0.2339 - val_loss: 2.5950 - val_accuracy: 0.2339\n",
      "Epoch 18/100\n",
      "255/255 - 1s - loss: 2.5909 - accuracy: 0.2341 - val_loss: 2.5946 - val_accuracy: 0.2339\n",
      "Epoch 19/100\n",
      "255/255 - 1s - loss: 2.5907 - accuracy: 0.2341 - val_loss: 2.5893 - val_accuracy: 0.2339\n",
      "Epoch 20/100\n",
      "255/255 - 1s - loss: 2.5900 - accuracy: 0.2339 - val_loss: 2.5983 - val_accuracy: 0.2339\n",
      "Epoch 21/100\n",
      "255/255 - 1s - loss: 2.5900 - accuracy: 0.2341 - val_loss: 2.5969 - val_accuracy: 0.2339\n",
      "Epoch 22/100\n",
      "255/255 - 1s - loss: 2.5899 - accuracy: 0.2341 - val_loss: 2.5951 - val_accuracy: 0.2339\n",
      "Epoch 23/100\n",
      "255/255 - 1s - loss: 2.5893 - accuracy: 0.2341 - val_loss: 2.5987 - val_accuracy: 0.2339\n",
      "Epoch 24/100\n",
      "255/255 - 1s - loss: 2.5895 - accuracy: 0.2341 - val_loss: 2.5881 - val_accuracy: 0.2339\n",
      "Epoch 25/100\n",
      "255/255 - 1s - loss: 2.5895 - accuracy: 0.2341 - val_loss: 2.5924 - val_accuracy: 0.2339\n",
      "Epoch 26/100\n",
      "255/255 - 1s - loss: 2.5887 - accuracy: 0.2341 - val_loss: 2.5991 - val_accuracy: 0.2339\n",
      "Epoch 27/100\n",
      "255/255 - 1s - loss: 2.5889 - accuracy: 0.2340 - val_loss: 2.5920 - val_accuracy: 0.2339\n",
      "Epoch 28/100\n",
      "255/255 - 1s - loss: 2.5889 - accuracy: 0.2341 - val_loss: 2.5899 - val_accuracy: 0.2339\n",
      "Epoch 29/100\n",
      "255/255 - 1s - loss: 2.5888 - accuracy: 0.2341 - val_loss: 2.5946 - val_accuracy: 0.2339\n",
      "Epoch 30/100\n",
      "255/255 - 1s - loss: 2.5891 - accuracy: 0.2341 - val_loss: 2.5870 - val_accuracy: 0.2339\n",
      "Epoch 31/100\n",
      "255/255 - 1s - loss: 2.5886 - accuracy: 0.2341 - val_loss: 2.5870 - val_accuracy: 0.2339\n",
      "Epoch 32/100\n",
      "255/255 - 1s - loss: 2.5888 - accuracy: 0.2341 - val_loss: 2.5886 - val_accuracy: 0.2339\n",
      "Epoch 33/100\n",
      "255/255 - 1s - loss: 2.5883 - accuracy: 0.2341 - val_loss: 2.5962 - val_accuracy: 0.2339\n",
      "Epoch 34/100\n",
      "255/255 - 1s - loss: 2.5881 - accuracy: 0.2341 - val_loss: 2.6020 - val_accuracy: 0.2339\n",
      "Epoch 35/100\n",
      "255/255 - 1s - loss: 2.5881 - accuracy: 0.2341 - val_loss: 2.5869 - val_accuracy: 0.2339\n",
      "Epoch 36/100\n",
      "255/255 - 1s - loss: 2.5882 - accuracy: 0.2341 - val_loss: 2.5974 - val_accuracy: 0.2339\n",
      "Epoch 37/100\n",
      "255/255 - 1s - loss: 2.5882 - accuracy: 0.2341 - val_loss: 2.5874 - val_accuracy: 0.2339\n",
      "Epoch 38/100\n",
      "255/255 - 1s - loss: 2.5885 - accuracy: 0.2340 - val_loss: 2.5937 - val_accuracy: 0.2339\n",
      "Epoch 39/100\n",
      "255/255 - 1s - loss: 2.5878 - accuracy: 0.2341 - val_loss: 2.5913 - val_accuracy: 0.2339\n",
      "Epoch 40/100\n",
      "255/255 - 1s - loss: 2.5875 - accuracy: 0.2341 - val_loss: 2.5959 - val_accuracy: 0.2332\n",
      "Epoch 41/100\n",
      "255/255 - 1s - loss: 2.5875 - accuracy: 0.2340 - val_loss: 2.5988 - val_accuracy: 0.2338\n",
      "Epoch 42/100\n",
      "255/255 - 1s - loss: 2.5875 - accuracy: 0.2341 - val_loss: 2.5883 - val_accuracy: 0.2339\n",
      "Epoch 43/100\n",
      "255/255 - 1s - loss: 2.5870 - accuracy: 0.2341 - val_loss: 2.5988 - val_accuracy: 0.2339\n",
      "Epoch 44/100\n",
      "255/255 - 1s - loss: 2.5872 - accuracy: 0.2340 - val_loss: 2.5961 - val_accuracy: 0.2339\n",
      "Epoch 45/100\n",
      "255/255 - 1s - loss: 2.5873 - accuracy: 0.2340 - val_loss: 2.5948 - val_accuracy: 0.2339\n",
      "Epoch 46/100\n",
      "255/255 - 1s - loss: 2.5873 - accuracy: 0.2341 - val_loss: 2.5886 - val_accuracy: 0.2339\n",
      "Epoch 47/100\n",
      "255/255 - 1s - loss: 2.5872 - accuracy: 0.2341 - val_loss: 2.5861 - val_accuracy: 0.2339\n",
      "Epoch 48/100\n",
      "255/255 - 1s - loss: 2.5874 - accuracy: 0.2341 - val_loss: 2.5900 - val_accuracy: 0.2339\n",
      "Epoch 49/100\n",
      "255/255 - 1s - loss: 2.5872 - accuracy: 0.2340 - val_loss: 2.5861 - val_accuracy: 0.2339\n",
      "Epoch 50/100\n",
      "255/255 - 1s - loss: 2.5868 - accuracy: 0.2341 - val_loss: 2.5959 - val_accuracy: 0.2339\n",
      "Epoch 51/100\n",
      "255/255 - 1s - loss: 2.5869 - accuracy: 0.2340 - val_loss: 2.5868 - val_accuracy: 0.2339\n",
      "Epoch 52/100\n",
      "255/255 - 1s - loss: 2.5871 - accuracy: 0.2340 - val_loss: 2.5901 - val_accuracy: 0.2339\n",
      "Epoch 53/100\n",
      "255/255 - 1s - loss: 2.5870 - accuracy: 0.2341 - val_loss: 2.5877 - val_accuracy: 0.2339\n",
      "Epoch 54/100\n",
      "255/255 - 1s - loss: 2.5871 - accuracy: 0.2340 - val_loss: 2.5908 - val_accuracy: 0.2339\n",
      "Epoch 55/100\n",
      "255/255 - 1s - loss: 2.5872 - accuracy: 0.2341 - val_loss: 2.5863 - val_accuracy: 0.2339\n",
      "Epoch 56/100\n",
      "255/255 - 1s - loss: 2.5872 - accuracy: 0.2341 - val_loss: 2.6008 - val_accuracy: 0.2339\n",
      "Epoch 57/100\n",
      "255/255 - 1s - loss: 2.5867 - accuracy: 0.2341 - val_loss: 2.5899 - val_accuracy: 0.2339\n",
      "Epoch 58/100\n",
      "255/255 - 1s - loss: 2.5864 - accuracy: 0.2341 - val_loss: 2.5866 - val_accuracy: 0.2339\n",
      "Epoch 59/100\n",
      "255/255 - 1s - loss: 2.5862 - accuracy: 0.2340 - val_loss: 2.5972 - val_accuracy: 0.2339\n",
      "Epoch 60/100\n",
      "255/255 - 1s - loss: 2.5863 - accuracy: 0.2340 - val_loss: 2.5866 - val_accuracy: 0.2339\n",
      "Epoch 61/100\n",
      "255/255 - 1s - loss: 2.5864 - accuracy: 0.2340 - val_loss: 2.5868 - val_accuracy: 0.2339\n",
      "Epoch 62/100\n",
      "255/255 - 1s - loss: 2.5864 - accuracy: 0.2340 - val_loss: 2.5858 - val_accuracy: 0.2332\n",
      "Epoch 63/100\n",
      "255/255 - 1s - loss: 2.5864 - accuracy: 0.2340 - val_loss: 2.5948 - val_accuracy: 0.2339\n",
      "Epoch 64/100\n",
      "255/255 - 1s - loss: 2.5864 - accuracy: 0.2340 - val_loss: 2.5874 - val_accuracy: 0.2338\n",
      "Epoch 65/100\n",
      "255/255 - 1s - loss: 2.5866 - accuracy: 0.2340 - val_loss: 2.5898 - val_accuracy: 0.2339\n",
      "Epoch 66/100\n",
      "255/255 - 1s - loss: 2.5865 - accuracy: 0.2341 - val_loss: 2.5878 - val_accuracy: 0.2339\n",
      "Epoch 67/100\n",
      "255/255 - 1s - loss: 2.5866 - accuracy: 0.2340 - val_loss: 2.5871 - val_accuracy: 0.2339\n",
      "Epoch 68/100\n",
      "255/255 - 1s - loss: 2.5868 - accuracy: 0.2341 - val_loss: 2.5911 - val_accuracy: 0.2339\n",
      "Epoch 69/100\n",
      "255/255 - 1s - loss: 2.5867 - accuracy: 0.2341 - val_loss: 2.5868 - val_accuracy: 0.2339\n",
      "Epoch 70/100\n",
      "255/255 - 1s - loss: 2.5868 - accuracy: 0.2340 - val_loss: 2.5954 - val_accuracy: 0.2339\n",
      "Epoch 71/100\n",
      "255/255 - 1s - loss: 2.5868 - accuracy: 0.2341 - val_loss: 2.5983 - val_accuracy: 0.2339\n",
      "Epoch 72/100\n",
      "255/255 - 1s - loss: 2.5867 - accuracy: 0.2340 - val_loss: 2.5914 - val_accuracy: 0.2338\n",
      "Epoch 73/100\n",
      "255/255 - 1s - loss: 2.5867 - accuracy: 0.2341 - val_loss: 2.5877 - val_accuracy: 0.2339\n",
      "Epoch 74/100\n",
      "255/255 - 1s - loss: 2.5867 - accuracy: 0.2340 - val_loss: 2.5961 - val_accuracy: 0.2338\n",
      "Epoch 75/100\n",
      "255/255 - 1s - loss: 2.5867 - accuracy: 0.2341 - val_loss: 2.5942 - val_accuracy: 0.2339\n",
      "Epoch 76/100\n",
      "255/255 - 1s - loss: 2.5869 - accuracy: 0.2341 - val_loss: 2.5894 - val_accuracy: 0.2339\n",
      "Epoch 77/100\n",
      "255/255 - 1s - loss: 2.5867 - accuracy: 0.2341 - val_loss: 2.5866 - val_accuracy: 0.2338\n",
      "Epoch 78/100\n",
      "255/255 - 1s - loss: 2.5866 - accuracy: 0.2340 - val_loss: 2.5871 - val_accuracy: 0.2339\n",
      "Epoch 79/100\n",
      "255/255 - 1s - loss: 2.5869 - accuracy: 0.2340 - val_loss: 2.5965 - val_accuracy: 0.2339\n",
      "Epoch 80/100\n",
      "255/255 - 1s - loss: 2.5860 - accuracy: 0.2340 - val_loss: 2.6023 - val_accuracy: 0.2339\n",
      "Epoch 81/100\n",
      "255/255 - 1s - loss: 2.5868 - accuracy: 0.2340 - val_loss: 2.5890 - val_accuracy: 0.2339\n",
      "Epoch 82/100\n",
      "255/255 - 1s - loss: 2.5863 - accuracy: 0.2340 - val_loss: 2.5928 - val_accuracy: 0.2339\n",
      "Epoch 83/100\n",
      "255/255 - 1s - loss: 2.5862 - accuracy: 0.2341 - val_loss: 2.5870 - val_accuracy: 0.2339\n",
      "Epoch 84/100\n",
      "255/255 - 1s - loss: 2.5863 - accuracy: 0.2341 - val_loss: 2.5849 - val_accuracy: 0.2339\n",
      "Epoch 85/100\n",
      "255/255 - 1s - loss: 2.5860 - accuracy: 0.2341 - val_loss: 2.5919 - val_accuracy: 0.2332\n",
      "Epoch 86/100\n",
      "255/255 - 1s - loss: 2.5861 - accuracy: 0.2340 - val_loss: 2.5910 - val_accuracy: 0.2338\n",
      "Epoch 87/100\n",
      "255/255 - 1s - loss: 2.5859 - accuracy: 0.2340 - val_loss: 2.6064 - val_accuracy: 0.2339\n",
      "Epoch 88/100\n",
      "255/255 - 1s - loss: 2.5861 - accuracy: 0.2341 - val_loss: 2.5932 - val_accuracy: 0.2339\n",
      "Epoch 89/100\n",
      "255/255 - 1s - loss: 2.5861 - accuracy: 0.2340 - val_loss: 2.5871 - val_accuracy: 0.2339\n",
      "Epoch 90/100\n",
      "255/255 - 1s - loss: 2.5860 - accuracy: 0.2340 - val_loss: 2.5931 - val_accuracy: 0.2339\n",
      "Epoch 91/100\n",
      "255/255 - 1s - loss: 2.5859 - accuracy: 0.2341 - val_loss: 2.5861 - val_accuracy: 0.2339\n",
      "Epoch 92/100\n",
      "255/255 - 1s - loss: 2.5858 - accuracy: 0.2340 - val_loss: 2.5862 - val_accuracy: 0.2339\n",
      "Epoch 93/100\n",
      "255/255 - 1s - loss: 2.5857 - accuracy: 0.2340 - val_loss: 2.5883 - val_accuracy: 0.2339\n",
      "Epoch 94/100\n",
      "255/255 - 1s - loss: 2.5861 - accuracy: 0.2340 - val_loss: 2.5854 - val_accuracy: 0.2339\n",
      "Epoch 95/100\n",
      "255/255 - 1s - loss: 2.5861 - accuracy: 0.2340 - val_loss: 2.5865 - val_accuracy: 0.2339\n",
      "Epoch 96/100\n",
      "255/255 - 1s - loss: 2.5858 - accuracy: 0.2341 - val_loss: 2.5925 - val_accuracy: 0.2339\n",
      "Epoch 97/100\n",
      "255/255 - 1s - loss: 2.5860 - accuracy: 0.2341 - val_loss: 2.5998 - val_accuracy: 0.2339\n",
      "Epoch 98/100\n",
      "255/255 - 1s - loss: 2.5859 - accuracy: 0.2341 - val_loss: 2.5954 - val_accuracy: 0.2332\n",
      "Epoch 99/100\n",
      "255/255 - 1s - loss: 2.5858 - accuracy: 0.2340 - val_loss: 2.5902 - val_accuracy: 0.2338\n",
      "Epoch 100/100\n",
      "255/255 - 1s - loss: 2.5855 - accuracy: 0.2340 - val_loss: 2.5868 - val_accuracy: 0.2339\n",
      "Training duration: 54.51343321800232\n",
      "1359/1359 [==============================] - 2s 1ms/step - loss: 2.5868 - accuracy: 0.2339\n",
      "\n",
      "Network's test loss and accuracy duration: 56.362284421920776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 500)               9000      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 100)               25100     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 159,350\n",
      "Trainable params: 159,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# y_train = np_utils.to_categorical(y_train, 100)\n",
    "# y_test = np_utils.to_categorical(y_test, 100)\n",
    "\n",
    "nn_model = init_model()\n",
    "history = run_network(model = nn_model, epochs=100)\n",
    "plot_losses(history)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPr0dZ4wyC8oM28XFuSJtJg",
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
